{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.nn import Module,Sequential,Linear,Conv2d,BatchNorm2d,ReLU,MaxPool2d\n",
    "from torch.utils.data import DataLoader\n",
    "import pathlib\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=3):\n",
    "        #giving default number of classes as 3\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Input shape= (batch_size,3,150,150)\n",
    "        # batch_size images in a batch x 3 channels(r,g,b) in an image x (150*150) pixels in an image.\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Applies 12 different filters and therefore obtains 12 different activation maps for all images in the btatch so only depth is changed\n",
    "        #Shape= (batch_size,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Number of features is only fed as the batchnorm input\n",
    "        #Shape= (batch_size,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (batch_size,12,150,150)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (batch_size,12,75,75)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (batch_size,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (batch_size,20,75,75)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (batch_size,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (batch_size,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (batch_size,32,75,75)\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Feed forwad function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "        #Above output will be in matrix form, with shape (batch_size,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "        #C-1 inferrs values from other dimensions to ensure the final dimension is equla to the previous end multiplication result(batch_size,32,75,75)\n",
    "        #batch_size entries with each entry as a single arra flattened from previous matrices . Each array length = 32*75*75\n",
    "            \n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(150),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes to be made in below cell :\n",
    "\n",
    "Make a way to slice the dataset for each client\n",
    "Compile everything to one single class\n",
    "So, take number of data samples and batch size as an input to the model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = '/Users/tarunvisvar/Downloads/Dataset/Handwriting/Handwriting-subset/Train'\n",
    "test_path = '/Users/tarunvisvar/Downloads/Dataset/Handwriting/Handwriting-subset/Test'\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform = preprocess),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform = preprocess),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pathlib.Path(train_path)\n",
    "classes = [dir.name for dir in root.iterdir()]\n",
    "classes.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reversal', 'Normal', 'Corrected']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes = 3)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the size of training and testing images\n",
    "\n",
    "train_count=len(glob.glob(train_path+'/**/*.png'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1040)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count,test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/tarunvisvar/Downloads/SimpleCNN.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# The images(in batches) are preprocessed while brought up by the trainloader itself\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# The images(in batches) are passed through various layers and predictions are made.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Those are the outputs and are compared with the labels\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# The output is a batch_size length vector containing predicted output for batch_size images\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func(outputs,labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward() \u001b[39m# backpropagation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep() \u001b[39m# Updates the weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#print(\"loss.data = \",loss.data)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# For each image, we must add the loss to training loss. But loss is given for a batch by the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# So, we take the loss for a batch and multiply it with the batch size to get the loss for each image in an approximate manner\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "     model.train()\n",
    "     #Model will be in training mode and takes place on training dataset\n",
    "     train_loss = 0.0\n",
    "     train_accuracy = 0.0\n",
    "     for images,labels in train_loader:\n",
    "          # The loop runs for 'number of batches' times \n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(images) \n",
    "          # The images(in batches) are preprocessed while brought up by the trainloader itself\n",
    "          # The images(in batches) are passed through various layers and predictions are made.\n",
    "          # Those are the outputs and are compared with the labels\n",
    "          # The output is a batch_size length vector containing predicted output for batch_size images\n",
    "\n",
    "          loss = loss_func(outputs,labels)\n",
    "          loss.backward() # backpropagation\n",
    "          optimizer.step() # Updates the weights\n",
    "          #print(\"loss.data = \",loss.data)\n",
    "          \n",
    "          # For each image, we must add the loss to training loss. But loss is given for a batch by the model\n",
    "          # So, we take the loss for a batch and multiply it with the batch size to get the loss for each image in an approximate manner\n",
    "\n",
    "          train_loss += loss.data*batch_size\n",
    "          #print(outputs.data) #outputs will be of size 10 x 3, for 10 images in a batch and 3 predictions for each image in a batch\n",
    "          _,predictions = torch.max(outputs.data,1)\n",
    "          #print(predictions) #predictions will contain the indices of the highest value outputed for each image. Therefore, predictions will contain 10(batch_size) values of the indices(hence also the classes)\n",
    "          train_accuracy+=int(torch.sum(predictions==labels.data))\n",
    "     train_accuracy /= train_count\n",
    "     train_loss /= train_count\n",
    "     print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy))\n",
    "     model.eval()\n",
    "     #Modle will eb in the mode on evaluating on test dataset\n",
    "     test_accuracy = 0.0\n",
    "     for images,labels in test_loader:\n",
    "          outputs = model(images)\n",
    "          _,predictions = torch.max(outputs.data,1)\n",
    "          #print(outputs.data)\n",
    "          test_accuracy += int(torch.sum(predictions==labels.data))\n",
    "     test_accuracy /= test_count\n",
    "     print(\"Test accuracy =  \",str(test_accuracy))\n",
    "     if test_accuracy>best_accuracy:\n",
    "        torch.save(model,'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9548076923076924\n"
     ]
    }
   ],
   "source": [
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load('best_checkpoint.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight Parameter containing:\n",
      "tensor([[[[-0.0798,  0.1037, -0.0650],\n",
      "          [-0.1469, -0.0271, -0.0710],\n",
      "          [ 0.0055, -0.1653,  0.1933]],\n",
      "\n",
      "         [[-0.1393,  0.0436, -0.0150],\n",
      "          [-0.0965, -0.0228, -0.0916],\n",
      "          [-0.0106, -0.0282,  0.0208]],\n",
      "\n",
      "         [[-0.1845,  0.0477,  0.1889],\n",
      "          [ 0.0841,  0.1630,  0.1174],\n",
      "          [-0.0038,  0.1136, -0.1315]]],\n",
      "\n",
      "\n",
      "        [[[-0.0660, -0.0337, -0.1542],\n",
      "          [-0.1738, -0.0893,  0.0488],\n",
      "          [-0.0170, -0.1456, -0.0249]],\n",
      "\n",
      "         [[ 0.0316,  0.0687,  0.1745],\n",
      "          [-0.1044,  0.1226,  0.1334],\n",
      "          [ 0.0947, -0.0266, -0.0758]],\n",
      "\n",
      "         [[-0.1096, -0.0644,  0.1631],\n",
      "          [-0.0897, -0.0504, -0.1465],\n",
      "          [-0.2277, -0.0462, -0.1048]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0362, -0.0673, -0.1224],\n",
      "          [ 0.1730, -0.0061, -0.1046],\n",
      "          [-0.1686,  0.0575, -0.0285]],\n",
      "\n",
      "         [[ 0.1916,  0.0630, -0.1797],\n",
      "          [ 0.0075,  0.0879, -0.0115],\n",
      "          [ 0.1452, -0.0021,  0.0287]],\n",
      "\n",
      "         [[ 0.1965, -0.1049, -0.1007],\n",
      "          [-0.0998,  0.0963,  0.0776],\n",
      "          [ 0.1219, -0.0937, -0.1701]]],\n",
      "\n",
      "\n",
      "        [[[-0.1245, -0.1916, -0.1136],\n",
      "          [-0.0667, -0.1148,  0.1505],\n",
      "          [-0.1050,  0.0130,  0.1876]],\n",
      "\n",
      "         [[ 0.1079, -0.0485, -0.1661],\n",
      "          [ 0.1335,  0.0579,  0.0667],\n",
      "          [ 0.1631,  0.1537,  0.1758]],\n",
      "\n",
      "         [[ 0.0680,  0.0486, -0.0123],\n",
      "          [ 0.0852,  0.1067,  0.1821],\n",
      "          [ 0.1722, -0.0371,  0.1240]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0751, -0.0367,  0.0088],\n",
      "          [-0.1362,  0.0198,  0.1079],\n",
      "          [ 0.0053,  0.0632,  0.0123]],\n",
      "\n",
      "         [[-0.0688, -0.1451, -0.1058],\n",
      "          [ 0.0238, -0.0126, -0.0108],\n",
      "          [ 0.1096,  0.0588,  0.0729]],\n",
      "\n",
      "         [[-0.0756, -0.0781, -0.1848],\n",
      "          [ 0.1798,  0.0349, -0.0838],\n",
      "          [-0.0944,  0.0610,  0.1409]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1538, -0.0918, -0.1600],\n",
      "          [-0.1337, -0.0477,  0.1340],\n",
      "          [-0.1088,  0.1302, -0.0423]],\n",
      "\n",
      "         [[ 0.0208,  0.0596,  0.0695],\n",
      "          [-0.1874, -0.0105, -0.1406],\n",
      "          [-0.0916, -0.1145, -0.0830]],\n",
      "\n",
      "         [[ 0.1070,  0.1266,  0.0411],\n",
      "          [-0.0954,  0.0371, -0.0943],\n",
      "          [ 0.0101, -0.0192, -0.0152]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0635,  0.1612,  0.0505],\n",
      "          [-0.0471,  0.1586,  0.0335],\n",
      "          [-0.1935, -0.0531,  0.1269]],\n",
      "\n",
      "         [[ 0.0130, -0.1216,  0.0930],\n",
      "          [ 0.1254, -0.1761, -0.1889],\n",
      "          [ 0.1364,  0.1576,  0.0809]],\n",
      "\n",
      "         [[ 0.0343, -0.0253,  0.0140],\n",
      "          [-0.1776,  0.0810,  0.0514],\n",
      "          [ 0.0317, -0.0467,  0.0403]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0568, -0.1332,  0.1599],\n",
      "          [ 0.1280, -0.1556,  0.0289],\n",
      "          [-0.0185, -0.0851,  0.1838]],\n",
      "\n",
      "         [[ 0.1825, -0.0269, -0.1852],\n",
      "          [-0.0335,  0.0972,  0.0600],\n",
      "          [ 0.0735,  0.1065, -0.0982]],\n",
      "\n",
      "         [[ 0.0952, -0.1833, -0.1784],\n",
      "          [-0.0643,  0.1014, -0.0734],\n",
      "          [ 0.1112,  0.1556, -0.0703]]],\n",
      "\n",
      "\n",
      "        [[[-0.0870,  0.1634,  0.0581],\n",
      "          [ 0.0443, -0.1432,  0.1911],\n",
      "          [ 0.1633, -0.1411,  0.0798]],\n",
      "\n",
      "         [[ 0.0441, -0.0815,  0.0375],\n",
      "          [ 0.1486, -0.1656, -0.0641],\n",
      "          [ 0.1327,  0.1087,  0.1785]],\n",
      "\n",
      "         [[-0.1884, -0.1639, -0.0007],\n",
      "          [-0.0458,  0.0199,  0.1482],\n",
      "          [-0.1150,  0.1042, -0.1309]]],\n",
      "\n",
      "\n",
      "        [[[-0.1522, -0.1958, -0.1266],\n",
      "          [ 0.0510, -0.1174,  0.0716],\n",
      "          [ 0.0413, -0.1612,  0.1684]],\n",
      "\n",
      "         [[ 0.1293,  0.1614, -0.1751],\n",
      "          [ 0.1188, -0.1938,  0.0313],\n",
      "          [-0.0910,  0.1451, -0.1276]],\n",
      "\n",
      "         [[-0.1259, -0.0701, -0.1574],\n",
      "          [-0.1177, -0.1581,  0.0148],\n",
      "          [ 0.1299,  0.1686, -0.1155]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0581, -0.1714, -0.0903],\n",
      "          [ 0.0260, -0.1778, -0.0246],\n",
      "          [ 0.0729, -0.1597,  0.1831]],\n",
      "\n",
      "         [[ 0.1082,  0.1880, -0.1874],\n",
      "          [ 0.0286, -0.1439,  0.0965],\n",
      "          [-0.0122, -0.1227,  0.0440]],\n",
      "\n",
      "         [[ 0.0511,  0.0631,  0.1716],\n",
      "          [ 0.1594, -0.1143,  0.1428],\n",
      "          [ 0.1319,  0.0713,  0.0318]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0786, -0.1691, -0.1824],\n",
      "          [ 0.1993, -0.1850,  0.1166],\n",
      "          [-0.0638,  0.1079,  0.0834]],\n",
      "\n",
      "         [[ 0.1124,  0.1083,  0.0253],\n",
      "          [ 0.1308, -0.0418,  0.1543],\n",
      "          [-0.1664,  0.0500, -0.0988]],\n",
      "\n",
      "         [[-0.0148, -0.0939, -0.0882],\n",
      "          [ 0.1171,  0.0878,  0.1325],\n",
      "          [-0.0855, -0.0691, -0.0475]]]], requires_grad=True)\n",
      "conv1.bias Parameter containing:\n",
      "tensor([ 0.0102, -0.0696,  0.1525, -0.0433, -0.0668,  0.2225,  0.0032, -0.0186,\n",
      "         0.1248, -0.0308,  0.0862,  0.1895], requires_grad=True)\n",
      "bn1.weight Parameter containing:\n",
      "tensor([0.9994, 0.9993, 1.0228, 0.9983, 1.0157, 0.9928, 0.9963, 0.9974, 1.0051,\n",
      "        1.0021, 0.9844, 0.9886], requires_grad=True)\n",
      "bn1.bias Parameter containing:\n",
      "tensor([-0.0040,  0.0020, -0.0103, -0.0077,  0.0036, -0.0069, -0.0051, -0.0165,\n",
      "         0.0004,  0.0021, -0.0169, -0.0110], requires_grad=True)\n",
      "conv2.weight Parameter containing:\n",
      "tensor([[[[ 4.0014e-02, -5.5907e-02, -4.7229e-02],\n",
      "          [ 3.7686e-02, -3.2202e-02, -4.9195e-02],\n",
      "          [-7.9502e-02,  3.3697e-02, -4.6560e-02]],\n",
      "\n",
      "         [[ 3.9590e-02,  6.3127e-02,  6.1443e-02],\n",
      "          [-2.5887e-02, -1.2072e-02,  4.4082e-02],\n",
      "          [ 9.7406e-02,  7.7237e-02, -6.1352e-02]],\n",
      "\n",
      "         [[ 1.8543e-02, -9.9208e-02,  4.3228e-02],\n",
      "          [ 8.5202e-02, -6.4505e-03,  7.3152e-04],\n",
      "          [-4.0173e-02, -1.0298e-01,  7.9007e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.1851e-03, -7.1553e-02,  3.1610e-02],\n",
      "          [ 9.5946e-03,  2.0583e-02,  5.0493e-02],\n",
      "          [ 7.9969e-02,  1.0133e-01, -1.6662e-02]],\n",
      "\n",
      "         [[-3.9032e-02,  8.1860e-03,  7.1965e-02],\n",
      "          [-8.3357e-02,  7.5778e-02, -3.1367e-02],\n",
      "          [ 2.7208e-02, -1.9181e-02,  1.8413e-02]],\n",
      "\n",
      "         [[-9.1687e-02,  3.2724e-02, -2.8693e-03],\n",
      "          [ 5.0501e-03,  6.9578e-02, -1.8146e-02],\n",
      "          [ 4.3686e-02, -8.4151e-02, -6.2055e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5848e-02, -3.6793e-02, -4.1897e-02],\n",
      "          [-3.7775e-02,  2.5838e-02, -1.9028e-02],\n",
      "          [ 9.6510e-02, -7.8926e-02, -4.6590e-02]],\n",
      "\n",
      "         [[ 4.8535e-04, -1.7070e-02, -4.8887e-02],\n",
      "          [-5.2385e-02,  8.0104e-02,  6.5797e-02],\n",
      "          [ 1.6331e-02, -3.3751e-02,  1.2906e-02]],\n",
      "\n",
      "         [[-6.0361e-02, -5.1931e-02,  2.5622e-02],\n",
      "          [-9.8923e-03, -9.6130e-02,  8.8825e-02],\n",
      "          [ 8.6655e-02, -6.4556e-02,  2.6739e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.2051e-02, -2.0556e-02,  2.1916e-02],\n",
      "          [ 6.7402e-02,  5.3403e-02, -4.0664e-02],\n",
      "          [-3.1700e-02, -9.7505e-02,  3.2620e-02]],\n",
      "\n",
      "         [[ 1.0415e-01, -7.8946e-03, -1.0836e-02],\n",
      "          [-1.5064e-02,  7.6456e-02,  3.1564e-02],\n",
      "          [ 6.4166e-02, -3.9850e-02, -8.6927e-02]],\n",
      "\n",
      "         [[-4.8404e-02, -4.4930e-02,  8.2415e-02],\n",
      "          [-4.0944e-02,  3.4353e-02, -6.4601e-02],\n",
      "          [-3.1645e-03, -4.5144e-02,  4.9301e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6815e-02,  7.4193e-02,  2.0107e-02],\n",
      "          [-7.7793e-02, -4.8804e-02, -6.9463e-02],\n",
      "          [-6.7753e-02, -8.6936e-03, -1.0261e-02]],\n",
      "\n",
      "         [[ 3.7053e-02, -6.1070e-02,  5.9091e-02],\n",
      "          [-6.2052e-02, -1.8786e-02, -4.3860e-02],\n",
      "          [-3.1068e-02,  5.0248e-02,  9.0199e-02]],\n",
      "\n",
      "         [[-5.8770e-02, -5.1050e-02,  5.3379e-04],\n",
      "          [-3.8115e-02,  9.6788e-02,  4.7690e-02],\n",
      "          [-5.7355e-02,  5.5398e-03,  4.2280e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.2531e-02, -1.6631e-03, -9.5985e-02],\n",
      "          [-8.4051e-02,  6.7124e-02, -6.5893e-02],\n",
      "          [-1.7191e-02, -5.0920e-02, -5.3902e-03]],\n",
      "\n",
      "         [[-2.4229e-02,  4.3639e-02,  4.4766e-02],\n",
      "          [ 5.2287e-02, -1.7356e-02, -6.4244e-02],\n",
      "          [ 7.1957e-02, -4.8848e-02, -3.0468e-02]],\n",
      "\n",
      "         [[-9.6967e-02, -5.3787e-03,  2.4352e-02],\n",
      "          [ 5.2886e-02, -9.5142e-02, -4.3429e-02],\n",
      "          [-3.5549e-04,  4.5962e-02,  5.6549e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.2081e-02, -3.7568e-03,  2.5743e-02],\n",
      "          [ 4.0097e-02, -2.9460e-02,  2.6921e-02],\n",
      "          [ 1.2736e-02, -9.6810e-02,  3.2613e-02]],\n",
      "\n",
      "         [[-5.3341e-02,  2.5703e-03, -4.8784e-02],\n",
      "          [-2.1082e-02, -3.6177e-02,  3.8055e-02],\n",
      "          [-8.4561e-03,  4.9198e-02,  2.6666e-02]],\n",
      "\n",
      "         [[-1.0107e-01,  1.0222e-01,  4.3661e-02],\n",
      "          [-2.0441e-02,  9.0584e-02, -2.7187e-02],\n",
      "          [ 9.0540e-02,  1.0529e-01,  3.6167e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4996e-02,  2.5198e-02,  1.2151e-02],\n",
      "          [-4.3673e-02,  4.2069e-02,  4.7992e-02],\n",
      "          [ 5.1513e-03,  3.5167e-02,  1.6683e-02]],\n",
      "\n",
      "         [[-1.7889e-02,  6.0844e-02, -6.8696e-02],\n",
      "          [-2.2730e-02, -6.5304e-02, -8.2923e-02],\n",
      "          [-6.4870e-02, -2.3228e-02,  6.3641e-02]],\n",
      "\n",
      "         [[ 2.8828e-02,  6.7765e-02,  3.3898e-02],\n",
      "          [-6.6438e-02,  6.0304e-02, -8.6538e-02],\n",
      "          [-3.8728e-02,  8.2313e-02, -7.8175e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1538e-02, -7.9705e-03, -8.5056e-02],\n",
      "          [ 1.4047e-02, -9.7171e-02,  2.8431e-02],\n",
      "          [-8.5600e-02, -8.9397e-02,  3.9190e-02]],\n",
      "\n",
      "         [[ 5.5769e-02, -1.0290e-01,  1.1030e-02],\n",
      "          [-8.7339e-02,  6.6383e-02, -6.9731e-02],\n",
      "          [-4.4090e-02,  8.6868e-02,  1.4887e-02]],\n",
      "\n",
      "         [[ 6.9374e-02,  8.8109e-02,  7.9316e-02],\n",
      "          [-3.1610e-02, -6.9688e-02, -2.5596e-02],\n",
      "          [-5.0338e-02,  4.4092e-02, -1.8360e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.5870e-02, -8.0691e-02,  2.6138e-02],\n",
      "          [-3.3486e-02, -6.1911e-02, -1.9850e-02],\n",
      "          [-7.1353e-02,  1.4922e-02,  9.1242e-02]],\n",
      "\n",
      "         [[-4.0473e-02,  4.3822e-02, -1.0439e-01],\n",
      "          [ 2.0997e-03, -5.6579e-02, -4.1202e-02],\n",
      "          [ 4.5802e-02,  7.3890e-02,  8.1858e-02]],\n",
      "\n",
      "         [[-3.6663e-02, -9.7967e-02,  4.1897e-02],\n",
      "          [-6.7361e-02, -4.3654e-02, -8.9695e-02],\n",
      "          [-2.6478e-02,  2.5847e-02,  4.1467e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.2517e-02,  6.7993e-02,  3.5096e-02],\n",
      "          [ 2.8533e-03,  4.4402e-02, -3.1966e-02],\n",
      "          [-4.4770e-02,  2.9729e-02,  5.6516e-02]],\n",
      "\n",
      "         [[-2.6635e-02,  3.2937e-02,  3.9592e-02],\n",
      "          [-5.2866e-02,  1.5523e-02, -2.5416e-03],\n",
      "          [-1.2683e-02, -2.4462e-06, -9.0621e-02]],\n",
      "\n",
      "         [[-4.5831e-02, -6.7809e-02,  3.6842e-02],\n",
      "          [ 2.3329e-02,  9.3146e-03,  8.2909e-03],\n",
      "          [-8.2940e-02,  7.4213e-03, -6.9778e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.2988e-02, -4.6735e-02, -9.1570e-03],\n",
      "          [-3.0574e-02,  1.1746e-02,  1.2461e-02],\n",
      "          [-6.7488e-02, -6.6005e-02,  5.3716e-02]],\n",
      "\n",
      "         [[-2.4264e-02,  5.7186e-02, -6.4715e-02],\n",
      "          [-2.3766e-03,  1.9511e-02,  3.0709e-02],\n",
      "          [ 7.3509e-02, -2.1162e-03,  2.9385e-02]],\n",
      "\n",
      "         [[ 5.6059e-03,  2.4087e-02, -9.2260e-02],\n",
      "          [-7.1294e-02, -5.6747e-02, -7.1963e-02],\n",
      "          [-2.7150e-02,  1.1582e-02, -5.2399e-02]]]], requires_grad=True)\n",
      "conv2.bias Parameter containing:\n",
      "tensor([ 0.0530,  0.0346, -0.0375,  0.0596,  0.0410,  0.0490, -0.0820, -0.0820,\n",
      "        -0.0070, -0.0612, -0.0341, -0.0140,  0.0157,  0.0541,  0.0708, -0.0748,\n",
      "        -0.1023,  0.0604, -0.0005, -0.0665], requires_grad=True)\n",
      "conv3.weight Parameter containing:\n",
      "tensor([[[[ 5.8768e-02,  4.6348e-02,  1.9402e-02],\n",
      "          [ 4.8711e-02, -6.4123e-02, -3.9725e-02],\n",
      "          [ 3.3096e-02,  4.4966e-02,  2.9698e-03]],\n",
      "\n",
      "         [[ 4.3877e-02, -4.3724e-02,  2.6226e-02],\n",
      "          [-2.8318e-02, -4.6192e-02, -6.7605e-02],\n",
      "          [ 5.7979e-02,  1.9868e-02,  6.7468e-02]],\n",
      "\n",
      "         [[ 2.4604e-02, -2.7938e-03, -1.8175e-04],\n",
      "          [ 9.6448e-03,  4.9602e-02, -5.4484e-02],\n",
      "          [ 5.0274e-03,  6.3861e-02, -1.0053e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.4225e-02,  4.4866e-02,  3.9001e-02],\n",
      "          [-4.6630e-02, -6.3058e-02, -1.2914e-02],\n",
      "          [-6.9772e-02,  4.0487e-02, -8.6407e-03]],\n",
      "\n",
      "         [[-4.8353e-03, -5.9133e-02,  7.0127e-02],\n",
      "          [ 7.9317e-02,  6.8664e-03, -3.6274e-02],\n",
      "          [ 2.5016e-02, -3.3031e-02,  2.3384e-02]],\n",
      "\n",
      "         [[-5.6836e-02,  1.1937e-02, -7.0425e-02],\n",
      "          [-5.2147e-02,  7.6755e-02, -6.6607e-02],\n",
      "          [-1.1042e-02,  2.5939e-02, -1.1333e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5583e-02,  1.8841e-03,  6.8440e-02],\n",
      "          [ 6.9559e-02, -2.6320e-02, -7.1257e-02],\n",
      "          [-1.1573e-02,  1.0971e-02, -6.7598e-02]],\n",
      "\n",
      "         [[ 4.1140e-02, -1.9844e-02, -3.2464e-02],\n",
      "          [ 5.4037e-02,  4.2152e-02, -4.2910e-02],\n",
      "          [ 3.0023e-02, -3.2751e-02, -6.1222e-02]],\n",
      "\n",
      "         [[ 5.0119e-02, -2.6062e-02,  3.5857e-03],\n",
      "          [-5.6689e-02, -1.2678e-03, -5.9231e-02],\n",
      "          [ 5.9172e-02, -5.4227e-02,  5.7556e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.9744e-02, -6.3371e-03,  1.6208e-02],\n",
      "          [ 5.0217e-02,  1.4678e-02,  4.4197e-02],\n",
      "          [-8.7023e-02, -2.1387e-04,  1.4466e-02]],\n",
      "\n",
      "         [[ 3.9643e-02,  1.0173e-02, -5.2133e-02],\n",
      "          [-7.9631e-04, -3.0386e-02, -5.1320e-02],\n",
      "          [-1.5129e-03,  5.6429e-02,  9.9730e-06]],\n",
      "\n",
      "         [[-1.5501e-02,  5.3026e-03,  1.5187e-02],\n",
      "          [ 2.5478e-02, -1.3840e-02, -9.6759e-03],\n",
      "          [ 2.8428e-02, -2.0493e-02,  5.7612e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9405e-02,  2.9650e-03,  6.9084e-02],\n",
      "          [ 5.1607e-02, -2.9666e-02,  2.6162e-02],\n",
      "          [ 2.8851e-02,  8.6062e-03, -5.1475e-02]],\n",
      "\n",
      "         [[-4.6584e-02,  7.2794e-02,  1.0452e-02],\n",
      "          [-4.9768e-02, -4.3058e-02,  8.3995e-03],\n",
      "          [ 3.5680e-02,  1.4734e-02, -5.5315e-02]],\n",
      "\n",
      "         [[-2.7227e-02, -1.3503e-02,  7.2727e-02],\n",
      "          [ 6.4138e-02, -5.2266e-02,  2.5863e-02],\n",
      "          [-1.0637e-02, -4.4244e-02, -3.5295e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0458e-02,  6.5645e-02,  2.7821e-02],\n",
      "          [ 3.9545e-02,  4.1241e-02, -7.3643e-03],\n",
      "          [-1.6440e-02, -4.3270e-02,  6.6836e-02]],\n",
      "\n",
      "         [[-5.7261e-03, -8.0287e-02, -2.1687e-02],\n",
      "          [-6.5756e-02, -1.6177e-02,  7.1230e-03],\n",
      "          [ 2.2212e-02,  1.7317e-02, -5.9337e-02]],\n",
      "\n",
      "         [[ 1.3828e-02,  6.3652e-02,  6.2417e-02],\n",
      "          [ 2.6576e-02,  7.5047e-02, -2.3257e-02],\n",
      "          [ 2.1249e-02,  4.0419e-02,  3.7228e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.7871e-02,  5.3776e-02, -4.3583e-02],\n",
      "          [-1.2317e-03,  4.6768e-02,  8.6352e-02],\n",
      "          [-6.8155e-03,  2.9449e-02, -2.3930e-02]],\n",
      "\n",
      "         [[-1.9980e-02, -4.6385e-03, -6.5755e-02],\n",
      "          [-5.2241e-02,  8.6790e-02, -1.7476e-02],\n",
      "          [-2.7716e-02,  1.6506e-02,  6.0822e-02]],\n",
      "\n",
      "         [[ 8.0907e-03, -5.5256e-02,  6.1960e-02],\n",
      "          [-6.5317e-02, -6.4178e-02, -3.6862e-02],\n",
      "          [-2.6606e-02,  7.9347e-02, -3.5404e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.0442e-03, -5.1557e-02, -8.7241e-02],\n",
      "          [-7.4869e-02,  8.8118e-03, -1.4581e-02],\n",
      "          [ 4.9349e-02, -6.6756e-02, -8.6974e-03]],\n",
      "\n",
      "         [[-1.6738e-02, -7.2266e-02, -7.1439e-02],\n",
      "          [-9.5045e-02,  3.2359e-02, -5.6952e-02],\n",
      "          [-4.2939e-02, -5.1918e-02,  2.0900e-02]],\n",
      "\n",
      "         [[-3.2462e-02, -5.7525e-03,  7.4101e-02],\n",
      "          [-4.3220e-02,  4.1990e-03,  1.2793e-02],\n",
      "          [ 1.1821e-02,  3.9770e-02, -3.9485e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5946e-02,  6.2104e-02, -6.9960e-02],\n",
      "          [ 1.7692e-02,  2.1686e-02,  2.6641e-02],\n",
      "          [-2.2806e-03,  4.8634e-02, -4.3703e-02]],\n",
      "\n",
      "         [[ 5.7415e-02, -6.5309e-02, -3.1582e-02],\n",
      "          [ 7.4620e-02,  9.9386e-03,  6.0929e-02],\n",
      "          [ 5.7852e-02,  2.7312e-02, -1.4519e-02]],\n",
      "\n",
      "         [[ 3.6185e-02, -7.9359e-02,  2.8882e-02],\n",
      "          [-3.9332e-02, -1.5036e-02, -4.7492e-02],\n",
      "          [-3.8086e-02, -3.1762e-02,  5.8735e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7856e-02, -5.4338e-02,  3.1341e-04],\n",
      "          [ 3.3256e-03, -7.7972e-02, -5.3165e-02],\n",
      "          [-5.3769e-02, -5.6653e-02, -9.1722e-03]],\n",
      "\n",
      "         [[ 2.9319e-02, -7.2626e-02,  2.4372e-02],\n",
      "          [ 6.0985e-02,  2.1953e-02,  3.0245e-02],\n",
      "          [-5.6439e-02, -7.7705e-02, -6.3417e-02]],\n",
      "\n",
      "         [[-1.6708e-02,  3.0227e-02,  5.4205e-02],\n",
      "          [ 4.3890e-02, -2.9756e-02, -4.9321e-02],\n",
      "          [ 5.6737e-02,  5.8462e-02, -5.2802e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3085e-02,  2.1328e-02,  6.6119e-03],\n",
      "          [ 5.7172e-02, -3.7995e-02,  6.5733e-02],\n",
      "          [-1.0740e-02,  8.1665e-02, -2.8091e-02]],\n",
      "\n",
      "         [[ 3.2684e-02, -3.8046e-04,  1.6736e-02],\n",
      "          [ 8.0149e-02,  8.7577e-02, -5.5938e-02],\n",
      "          [ 6.0829e-03,  6.2246e-02, -1.9501e-02]],\n",
      "\n",
      "         [[-2.8971e-02, -6.7100e-02, -4.4008e-02],\n",
      "          [ 6.0982e-02, -5.5980e-02, -7.0815e-03],\n",
      "          [ 2.3405e-02,  7.0315e-03,  3.3949e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9181e-02,  1.3925e-02, -1.0567e-02],\n",
      "          [ 2.8197e-02, -9.7303e-02, -4.5112e-02],\n",
      "          [-7.6210e-02, -8.0681e-02,  2.8850e-02]],\n",
      "\n",
      "         [[-3.5075e-02,  3.4495e-02,  4.3541e-03],\n",
      "          [ 8.8967e-03,  2.1912e-02,  5.5768e-02],\n",
      "          [-7.3845e-02,  4.2380e-02, -3.5851e-02]],\n",
      "\n",
      "         [[ 2.1222e-02, -4.6554e-02, -3.5413e-02],\n",
      "          [ 4.1669e-02, -3.9474e-02, -5.0681e-02],\n",
      "          [-5.4927e-02,  2.9206e-02,  5.5491e-02]]]], requires_grad=True)\n",
      "conv3.bias Parameter containing:\n",
      "tensor([-0.0774,  0.0344,  0.0224,  0.0801,  0.0181, -0.0757, -0.0586, -0.0582,\n",
      "         0.0407, -0.0749, -0.0518, -0.0704, -0.0644,  0.0255,  0.0310, -0.0626,\n",
      "        -0.0165,  0.0250,  0.0407,  0.0218, -0.0815, -0.0246,  0.0632, -0.0239,\n",
      "         0.0491, -0.0402, -0.0717,  0.0097, -0.0480, -0.0459,  0.0417, -0.0595],\n",
      "       requires_grad=True)\n",
      "bn3.weight Parameter containing:\n",
      "tensor([0.9610, 0.9567, 0.9516, 0.9652, 0.9701, 0.9673, 0.9733, 0.9830, 0.9726,\n",
      "        0.9732, 0.9713, 0.9624, 0.9721, 0.9717, 0.9666, 0.9678, 0.9642, 0.9624,\n",
      "        0.9735, 0.9710, 0.9680, 0.9535, 0.9755, 0.9667, 0.9602, 0.9705, 0.9633,\n",
      "        0.9511, 0.9650, 0.9732, 0.9713, 0.9735], requires_grad=True)\n",
      "bn3.bias Parameter containing:\n",
      "tensor([-0.0327, -0.0279, -0.0329, -0.0366, -0.0294, -0.0317, -0.0222, -0.0174,\n",
      "        -0.0194, -0.0166, -0.0340, -0.0241, -0.0279, -0.0213, -0.0336, -0.0258,\n",
      "        -0.0260, -0.0267, -0.0290, -0.0340, -0.0283, -0.0310, -0.0314, -0.0336,\n",
      "        -0.0384, -0.0242, -0.0271, -0.0216, -0.0272, -0.0284, -0.0222, -0.0247],\n",
      "       requires_grad=True)\n",
      "fc.weight Parameter containing:\n",
      "tensor([[ 6.4322e-03,  6.7801e-04,  1.1136e-03,  ..., -5.8722e-04,\n",
      "          1.8650e-03, -4.0424e-05],\n",
      "        [ 4.5394e-03, -1.1800e-03, -1.4925e-03,  ..., -2.2207e-04,\n",
      "         -7.1843e-04, -2.3499e-03],\n",
      "        [-4.4152e-03, -7.0845e-04, -1.2224e-03,  ..., -1.4006e-03,\n",
      "         -8.8566e-04,  1.1581e-03]], requires_grad=True)\n",
      "fc.bias Parameter containing:\n",
      "tensor([-0.0016, -0.0019,  0.0014], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name,param in loaded_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548399"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference:\n",
    "\n",
    "Number of parameters in a model = around 5 and half lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HWRModel:\n",
    "    def __init__(self,data_path,batch_size,local_data_count):\n",
    "        self.batch_size = batch_size\n",
    "        self.train_path = data_path + '/Train'\n",
    "        self.test_path = data_path + '/Test'\n",
    "        self.local_data_count = local_data_count # Amount of data that a user can choose \n",
    "    \n",
    "    def preprocess(self,resize=150):\n",
    "        transformer = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(resize),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "            ]\n",
    "        )\n",
    "        return transformer   \n",
    "\n",
    "    def get_model(self):\n",
    "        model = ConvNet(num_classes = 3)\n",
    "        optimizer = Adam(model.parameters(), lr=0.001)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        return (model,optimizer,loss_func)\n",
    "    \n",
    "    #Add load dataset function.\n",
    "\n",
    "    def load_dataset(self):\n",
    "        train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(self.train_path,transform = self.preprocess()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(self.test_path,transform = self.preprocess()),\n",
    "    batch_size=batch_size, shuffle=True) \n",
    "\n",
    "        return(train_loader,test_loader)\n",
    "        \n",
    "    def train(self,num_epochs=10):\n",
    "        model,optimizer,loss_func = self.get_model()\n",
    "        best_accuracy = 0.0\n",
    "        train_loader,test_loader = self.load_dataset()\n",
    "        train_count=len(glob.glob(self.train_path+'/**/*.png'))\n",
    "        test_count=len(glob.glob(self.test_path+'/**/*.png'))\n",
    "\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            #Model will be in training mode and takes place on training dataset\n",
    "            train_loss = 0.0\n",
    "            train_accuracy = 0.0\n",
    "            for images,labels in train_loader:\n",
    "                # The loop runs for 'number of batches' times \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images) \n",
    "                # The images(in batches) are preprocessed while brought up by the trainloader itself\n",
    "                # The images(in batches) are passed through various layers and predictions are made.\n",
    "                # Those are the outputs and are compared with the labels\n",
    "                # The output is a batch_size length vector containing predicted output for batch_size images\n",
    "\n",
    "                loss = loss_func(outputs,labels)\n",
    "                loss.backward() # backpropagation\n",
    "                optimizer.step() # Updates the weights\n",
    "                #print(\"loss.data = \",loss.data)\n",
    "                \n",
    "                # For each image, we must add the loss to training loss. But loss is given for a batch by the model\n",
    "                # So, we take the loss for a batch and multiply it with the batch size to get the loss for each image in an approximate manner\n",
    "\n",
    "                train_loss += loss.data*batch_size\n",
    "                #print(outputs.data) #outputs will be of size 10 x 3, for 10 images in a batch and 3 predictions for each image in a batch\n",
    "                _,predictions = torch.max(outputs.data,1)\n",
    "                #print(predictions) #predictions will contain the indices of the highest value outputed for each image. Therefore, predictions will contain 10(batch_size) values of the indices(hence also the classes)\n",
    "                train_accuracy+=int(torch.sum(predictions==labels.data))\n",
    "            train_accuracy /= train_count\n",
    "            train_loss /= train_count\n",
    "            print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy))\n",
    "            model.eval()\n",
    "            #Modle will eb in the mode on evaluating on test dataset\n",
    "            test_accuracy = 0.0\n",
    "            for images,labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                _,predictions = torch.max(outputs.data,1)\n",
    "                #print(outputs.data)\n",
    "                test_accuracy += int(torch.sum(predictions==labels.data))\n",
    "            test_accuracy /= test_count\n",
    "            print(\"Test accuracy =  \",str(test_accuracy))\n",
    "            if test_accuracy>best_accuracy:\n",
    "                torch.save(model,'best_checkpoint.model')\n",
    "                best_accuracy=test_accuracy\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        loaded_model = torch.load('best_checkpoint.model')\n",
    "        params = dict()\n",
    "        for name,parameters in loaded_model.named_parameters():\n",
    "            params[name] = parameters\n",
    "        return params\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/tarunvisvar/Downloads/Dataset/Handwriting/Handwriting-subset'\n",
    "batch_size = 100\n",
    "local_data_count = 1000\n",
    "mymodel = HWRModel(data_path,batch_size,local_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(10.6635) Train Accuracy: 0.51725\n",
      "Test accuracy =   0.24423076923076922\n",
      "Epoch: 1 Train Loss: tensor(1.1727) Train Accuracy: 0.7435\n",
      "Test accuracy =   0.8153846153846154\n",
      "Epoch: 2 Train Loss: tensor(0.6347) Train Accuracy: 0.823\n",
      "Test accuracy =   0.7615384615384615\n",
      "Epoch: 3 Train Loss: tensor(0.5071) Train Accuracy: 0.84175\n",
      "Test accuracy =   0.9538461538461539\n",
      "Epoch: 4 Train Loss: tensor(0.4548) Train Accuracy: 0.85975\n",
      "Test accuracy =   0.9644230769230769\n",
      "Epoch: 5 Train Loss: tensor(0.3992) Train Accuracy: 0.873\n",
      "Test accuracy =   0.9375\n",
      "Epoch: 6 Train Loss: tensor(0.5683) Train Accuracy: 0.85475\n",
      "Test accuracy =   0.8480769230769231\n",
      "Epoch: 7 Train Loss: tensor(0.2934) Train Accuracy: 0.90375\n",
      "Test accuracy =   0.8692307692307693\n",
      "Epoch: 8 Train Loss: tensor(0.4118) Train Accuracy: 0.8815\n",
      "Test accuracy =   0.7817307692307692\n",
      "Epoch: 9 Train Loss: tensor(0.2989) Train Accuracy: 0.9005\n",
      "Test accuracy =   0.9759615384615384\n"
     ]
    }
   ],
   "source": [
    "mymodel.train(num_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1.weight': Parameter containing:\n",
       " tensor([[[[ 0.0341, -0.1215,  0.0108],\n",
       "           [-0.0100, -0.1124, -0.1251],\n",
       "           [-0.0024, -0.1855,  0.0289]],\n",
       " \n",
       "          [[ 0.0772, -0.1251,  0.1007],\n",
       "           [ 0.0745, -0.1237,  0.1196],\n",
       "           [-0.0823,  0.0489, -0.0373]],\n",
       " \n",
       "          [[-0.1249,  0.0107, -0.1002],\n",
       "           [-0.0348, -0.0368, -0.1515],\n",
       "           [-0.0325, -0.1573,  0.1918]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1690, -0.1520,  0.0385],\n",
       "           [-0.0491,  0.0280,  0.0843],\n",
       "           [ 0.1760,  0.1190,  0.0933]],\n",
       " \n",
       "          [[ 0.0328,  0.1423,  0.0173],\n",
       "           [-0.0836, -0.1788,  0.1195],\n",
       "           [-0.0968, -0.1616, -0.1491]],\n",
       " \n",
       "          [[-0.1856,  0.0442, -0.1287],\n",
       "           [-0.1686, -0.1574, -0.0446],\n",
       "           [-0.0516, -0.0112,  0.0941]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0022,  0.0936,  0.1511],\n",
       "           [ 0.0622, -0.0815,  0.0032],\n",
       "           [ 0.1183, -0.0808, -0.0458]],\n",
       " \n",
       "          [[-0.1068,  0.1701, -0.1422],\n",
       "           [ 0.0849, -0.1182, -0.0911],\n",
       "           [ 0.0581, -0.1590, -0.0811]],\n",
       " \n",
       "          [[-0.0828, -0.1729,  0.1080],\n",
       "           [-0.1938,  0.0017, -0.2174],\n",
       "           [-0.1710,  0.1698,  0.1278]]],\n",
       " \n",
       " \n",
       "         [[[-0.0997,  0.0996, -0.1812],\n",
       "           [ 0.0400, -0.0243, -0.1480],\n",
       "           [-0.0826,  0.0943, -0.1264]],\n",
       " \n",
       "          [[ 0.1636, -0.0236,  0.0983],\n",
       "           [ 0.1479,  0.0295, -0.1156],\n",
       "           [-0.1498, -0.1536,  0.1788]],\n",
       " \n",
       "          [[-0.1016,  0.1741,  0.1837],\n",
       "           [-0.0853,  0.0695,  0.0005],\n",
       "           [ 0.0300, -0.1326,  0.1147]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0177, -0.0486, -0.1701],\n",
       "           [ 0.0183,  0.0634, -0.1460],\n",
       "           [-0.0315, -0.0124,  0.0546]],\n",
       " \n",
       "          [[-0.0271, -0.1225,  0.1906],\n",
       "           [ 0.0654,  0.0210, -0.0236],\n",
       "           [-0.0775,  0.1138, -0.0898]],\n",
       " \n",
       "          [[ 0.1759,  0.1458, -0.1249],\n",
       "           [-0.1371,  0.0799,  0.0520],\n",
       "           [-0.0190, -0.1068,  0.1816]]],\n",
       " \n",
       " \n",
       "         [[[-0.1724,  0.1755,  0.1343],\n",
       "           [-0.0732, -0.0532,  0.1032],\n",
       "           [ 0.0425,  0.1242,  0.0800]],\n",
       " \n",
       "          [[-0.0649,  0.1061,  0.1414],\n",
       "           [-0.1097, -0.0634, -0.0085],\n",
       "           [-0.0056,  0.0191,  0.1101]],\n",
       " \n",
       "          [[ 0.0532, -0.1551,  0.0097],\n",
       "           [-0.0487, -0.1077,  0.0595],\n",
       "           [-0.1193, -0.1291,  0.1418]]],\n",
       " \n",
       " \n",
       "         [[[-0.1393,  0.0479, -0.1759],\n",
       "           [-0.1111, -0.0097,  0.1769],\n",
       "           [-0.0936, -0.0739, -0.1029]],\n",
       " \n",
       "          [[-0.0794,  0.1398,  0.1096],\n",
       "           [ 0.1384,  0.0777,  0.1120],\n",
       "           [ 0.1460, -0.1309, -0.1259]],\n",
       " \n",
       "          [[ 0.1389, -0.0368,  0.0517],\n",
       "           [ 0.0653,  0.1467, -0.0408],\n",
       "           [ 0.0932,  0.1170,  0.1553]]],\n",
       " \n",
       " \n",
       "         [[[-0.0945, -0.0353, -0.0849],\n",
       "           [ 0.1371,  0.1408,  0.0381],\n",
       "           [ 0.1881,  0.1258,  0.0364]],\n",
       " \n",
       "          [[-0.1757,  0.0093,  0.0896],\n",
       "           [-0.1354, -0.1227, -0.1565],\n",
       "           [ 0.0779,  0.0337, -0.1699]],\n",
       " \n",
       "          [[ 0.1853,  0.0354, -0.0891],\n",
       "           [ 0.1805,  0.0176,  0.0451],\n",
       "           [ 0.1051,  0.0145,  0.1499]]],\n",
       " \n",
       " \n",
       "         [[[-0.0283, -0.1136,  0.0121],\n",
       "           [ 0.0098, -0.1323,  0.1639],\n",
       "           [-0.1086, -0.1594,  0.0486]],\n",
       " \n",
       "          [[ 0.0331,  0.0059,  0.1655],\n",
       "           [ 0.1163,  0.0030,  0.1284],\n",
       "           [-0.2015,  0.1085, -0.0353]],\n",
       " \n",
       "          [[-0.1064, -0.0087, -0.0946],\n",
       "           [-0.1147, -0.0263,  0.1583],\n",
       "           [-0.0612,  0.0559, -0.1251]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1319, -0.0689, -0.1537],\n",
       "           [ 0.0473,  0.0956, -0.0826],\n",
       "           [ 0.1573,  0.1445, -0.1522]],\n",
       " \n",
       "          [[-0.1147, -0.0084, -0.1034],\n",
       "           [ 0.0394, -0.1681,  0.0706],\n",
       "           [-0.0339, -0.1318,  0.0902]],\n",
       " \n",
       "          [[ 0.1372,  0.0373,  0.1122],\n",
       "           [-0.0189,  0.1055,  0.0611],\n",
       "           [-0.0496,  0.0221, -0.0341]]],\n",
       " \n",
       " \n",
       "         [[[-0.0545,  0.1927,  0.1502],\n",
       "           [ 0.1004, -0.0273, -0.0870],\n",
       "           [-0.2008,  0.1365,  0.0900]],\n",
       " \n",
       "          [[-0.0201, -0.1261,  0.1381],\n",
       "           [-0.1232,  0.0257, -0.1035],\n",
       "           [ 0.0467,  0.0685, -0.0913]],\n",
       " \n",
       "          [[ 0.1606, -0.0469,  0.0131],\n",
       "           [ 0.0502, -0.1100, -0.1277],\n",
       "           [ 0.1294, -0.0295, -0.1628]]],\n",
       " \n",
       " \n",
       "         [[[-0.0019, -0.1761,  0.1016],\n",
       "           [-0.1497, -0.1506, -0.0597],\n",
       "           [ 0.0060,  0.0074, -0.1107]],\n",
       " \n",
       "          [[ 0.1732,  0.1450, -0.1625],\n",
       "           [-0.0483, -0.1723, -0.1428],\n",
       "           [-0.1978,  0.1345,  0.0613]],\n",
       " \n",
       "          [[-0.0971, -0.1638,  0.1804],\n",
       "           [-0.1384,  0.0485,  0.0088],\n",
       "           [-0.0300, -0.0783,  0.0049]]]], requires_grad=True),\n",
       " 'conv1.bias': Parameter containing:\n",
       " tensor([-0.0180, -0.1073, -0.1564,  0.0060, -0.1234,  0.1055, -0.0233, -0.0776,\n",
       "          0.1861, -0.0324, -0.0569,  0.1719], requires_grad=True),\n",
       " 'bn1.weight': Parameter containing:\n",
       " tensor([1.0018, 1.0065, 0.9939, 1.0251, 0.9888, 1.0104, 0.9900, 0.9918, 0.9940,\n",
       "         1.0012, 1.0062, 1.0005], requires_grad=True),\n",
       " 'bn1.bias': Parameter containing:\n",
       " tensor([-1.4238e-03,  8.4397e-03, -6.9606e-03,  9.8666e-03, -1.5940e-02,\n",
       "         -5.1063e-03, -1.9722e-02, -2.0659e-02, -6.3168e-03, -4.7332e-03,\n",
       "         -1.8156e-02,  7.2147e-05], requires_grad=True),\n",
       " 'conv2.weight': Parameter containing:\n",
       " tensor([[[[ 0.0362, -0.0270,  0.0414],\n",
       "           [-0.0432, -0.0620,  0.0340],\n",
       "           [ 0.0692,  0.0170, -0.0149]],\n",
       " \n",
       "          [[-0.1032, -0.0227, -0.0801],\n",
       "           [ 0.0566,  0.0683, -0.0557],\n",
       "           [-0.0699, -0.0144, -0.1012]],\n",
       " \n",
       "          [[-0.0338,  0.0635, -0.0090],\n",
       "           [-0.0771,  0.0838,  0.0330],\n",
       "           [-0.0458, -0.0906, -0.0887]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0828, -0.0186, -0.0856],\n",
       "           [ 0.0685, -0.0001, -0.0663],\n",
       "           [-0.0517, -0.0200, -0.0860]],\n",
       " \n",
       "          [[-0.0762, -0.0554,  0.0198],\n",
       "           [-0.0775,  0.1022, -0.0859],\n",
       "           [-0.0128,  0.0533, -0.0596]],\n",
       " \n",
       "          [[ 0.0202, -0.0196, -0.0041],\n",
       "           [-0.0217, -0.0577, -0.0366],\n",
       "           [-0.0104,  0.0210, -0.1005]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0425, -0.0717, -0.0367],\n",
       "           [-0.1011, -0.0539, -0.0509],\n",
       "           [-0.0548,  0.0590,  0.0599]],\n",
       " \n",
       "          [[-0.0952,  0.0616, -0.0033],\n",
       "           [ 0.0333, -0.0270,  0.0717],\n",
       "           [-0.0231, -0.0110, -0.0316]],\n",
       " \n",
       "          [[-0.0531, -0.0338,  0.0847],\n",
       "           [-0.0820, -0.0989,  0.0460],\n",
       "           [ 0.0702,  0.0348,  0.0841]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0612,  0.0131, -0.0869],\n",
       "           [-0.0136, -0.0109, -0.0689],\n",
       "           [ 0.0527,  0.0476, -0.0744]],\n",
       " \n",
       "          [[ 0.0279,  0.0815,  0.0577],\n",
       "           [ 0.0807, -0.0506, -0.0886],\n",
       "           [ 0.0555,  0.0499,  0.0297]],\n",
       " \n",
       "          [[ 0.0641, -0.0858,  0.0405],\n",
       "           [ 0.0487, -0.0300, -0.0755],\n",
       "           [-0.0500, -0.0074, -0.0384]]],\n",
       " \n",
       " \n",
       "         [[[-0.0286,  0.0444, -0.0288],\n",
       "           [ 0.0608,  0.0075, -0.0655],\n",
       "           [-0.0461, -0.0235,  0.0160]],\n",
       " \n",
       "          [[-0.0942, -0.0788,  0.0070],\n",
       "           [ 0.0161,  0.0193,  0.0902],\n",
       "           [-0.0580,  0.0571, -0.0708]],\n",
       " \n",
       "          [[ 0.0234, -0.0735, -0.0883],\n",
       "           [-0.0472,  0.0968,  0.0621],\n",
       "           [-0.0300,  0.0791,  0.0902]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0737, -0.0154, -0.0138],\n",
       "           [-0.0368, -0.0120,  0.0885],\n",
       "           [-0.0123,  0.0841,  0.0779]],\n",
       " \n",
       "          [[-0.0168, -0.0471, -0.0635],\n",
       "           [ 0.1167, -0.0418,  0.0129],\n",
       "           [ 0.0040,  0.0655, -0.0510]],\n",
       " \n",
       "          [[-0.0462,  0.0548, -0.0617],\n",
       "           [-0.0452, -0.0227,  0.0270],\n",
       "           [ 0.0786, -0.0656,  0.0654]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0133, -0.0788, -0.0619],\n",
       "           [ 0.0583,  0.0724, -0.0663],\n",
       "           [ 0.0868, -0.0016,  0.0268]],\n",
       " \n",
       "          [[-0.0673, -0.1033, -0.0319],\n",
       "           [ 0.0674, -0.0238, -0.0732],\n",
       "           [ 0.0250,  0.0331, -0.0378]],\n",
       " \n",
       "          [[ 0.0751, -0.0569,  0.0654],\n",
       "           [-0.0605, -0.0542,  0.0653],\n",
       "           [-0.0749, -0.0874, -0.0575]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0293,  0.0377,  0.0458],\n",
       "           [-0.0986,  0.0208, -0.0710],\n",
       "           [-0.1099, -0.0279, -0.0305]],\n",
       " \n",
       "          [[ 0.0046,  0.1010,  0.0635],\n",
       "           [-0.0316, -0.0897, -0.0006],\n",
       "           [-0.0038, -0.0811, -0.0529]],\n",
       " \n",
       "          [[ 0.0148, -0.0024, -0.0505],\n",
       "           [ 0.0667, -0.0933, -0.0635],\n",
       "           [-0.0087,  0.0840,  0.0413]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0014, -0.0767, -0.0709],\n",
       "           [ 0.0291,  0.0064, -0.0623],\n",
       "           [ 0.0412, -0.0082,  0.0480]],\n",
       " \n",
       "          [[-0.0388, -0.0999,  0.0768],\n",
       "           [-0.0151, -0.0893, -0.0558],\n",
       "           [-0.0195, -0.0754, -0.0262]],\n",
       " \n",
       "          [[-0.0927, -0.0682,  0.0289],\n",
       "           [-0.0833, -0.0596, -0.0771],\n",
       "           [-0.0825, -0.0786,  0.0537]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0640, -0.0715, -0.0268],\n",
       "           [-0.0791,  0.0469,  0.0269],\n",
       "           [ 0.0139, -0.0026,  0.0373]],\n",
       " \n",
       "          [[-0.0374, -0.0303, -0.0576],\n",
       "           [-0.0327,  0.0607,  0.0545],\n",
       "           [-0.1053,  0.0657, -0.0792]],\n",
       " \n",
       "          [[-0.0830, -0.0100, -0.0998],\n",
       "           [-0.0608, -0.0915, -0.0190],\n",
       "           [ 0.0708, -0.0606, -0.0793]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0249, -0.0737,  0.0367],\n",
       "           [-0.0406,  0.0895,  0.0221],\n",
       "           [-0.0444, -0.0527, -0.0067]],\n",
       " \n",
       "          [[-0.0404, -0.0347,  0.0595],\n",
       "           [-0.0131, -0.0355,  0.0086],\n",
       "           [-0.0630,  0.0725,  0.0722]],\n",
       " \n",
       "          [[-0.0728,  0.0848,  0.0554],\n",
       "           [-0.0401,  0.0160, -0.0009],\n",
       "           [ 0.0615, -0.0675, -0.1011]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0291,  0.0261, -0.0544],\n",
       "           [-0.0846,  0.0356,  0.0308],\n",
       "           [-0.1048,  0.0555,  0.0239]],\n",
       " \n",
       "          [[-0.0300, -0.0550,  0.0357],\n",
       "           [-0.0068,  0.0740, -0.0369],\n",
       "           [-0.0103, -0.0082, -0.0468]],\n",
       " \n",
       "          [[-0.1026, -0.0634,  0.0274],\n",
       "           [-0.0501,  0.0100, -0.0518],\n",
       "           [ 0.0667, -0.0048, -0.0279]]]], requires_grad=True),\n",
       " 'conv2.bias': Parameter containing:\n",
       " tensor([-0.0874,  0.0454, -0.0868,  0.0136, -0.0300,  0.0452,  0.0116, -0.0887,\n",
       "          0.0221, -0.0456,  0.0334, -0.0325, -0.0868,  0.0386,  0.0281, -0.0634,\n",
       "          0.0605, -0.0715,  0.0099,  0.0697], requires_grad=True),\n",
       " 'conv3.weight': Parameter containing:\n",
       " tensor([[[[ 3.1609e-02, -4.1173e-02,  8.6603e-02],\n",
       "           [-4.2154e-02,  8.6817e-02,  6.3759e-02],\n",
       "           [-4.8604e-03,  5.6809e-02, -3.4311e-02]],\n",
       " \n",
       "          [[-2.1755e-03, -1.2081e-02,  2.5943e-02],\n",
       "           [ 9.0195e-02, -5.6303e-02,  4.5093e-02],\n",
       "           [ 6.1017e-02, -5.4422e-02, -2.8158e-02]],\n",
       " \n",
       "          [[ 8.7666e-02,  6.6290e-02,  3.8012e-02],\n",
       "           [-3.8015e-02, -9.8347e-03, -7.8711e-02],\n",
       "           [-2.9176e-02, -7.0572e-02,  1.3831e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.0658e-02, -5.4720e-02,  7.0800e-03],\n",
       "           [-2.0665e-02,  7.4484e-02,  5.4812e-02],\n",
       "           [-5.3131e-03,  5.9769e-03, -7.3464e-02]],\n",
       " \n",
       "          [[-4.1716e-02, -3.4341e-03, -7.2289e-02],\n",
       "           [ 1.8113e-03, -3.3480e-02, -6.1412e-02],\n",
       "           [-4.1369e-02,  2.5378e-02,  1.7078e-02]],\n",
       " \n",
       "          [[-2.3527e-03,  1.9270e-02,  2.8696e-02],\n",
       "           [-2.8935e-02, -1.4089e-03,  8.1485e-02],\n",
       "           [-7.3973e-03, -5.5916e-02, -4.7326e-03]]],\n",
       " \n",
       " \n",
       "         [[[-5.2922e-02,  3.7719e-02, -2.7178e-02],\n",
       "           [-2.8297e-02, -2.8158e-02, -8.3347e-02],\n",
       "           [ 6.5561e-02, -5.4735e-02, -3.5798e-02]],\n",
       " \n",
       "          [[ 4.0195e-02,  2.6306e-02, -2.8970e-02],\n",
       "           [ 2.3695e-02, -3.2610e-02,  3.7509e-02],\n",
       "           [-3.2315e-02, -7.8064e-02, -5.5366e-02]],\n",
       " \n",
       "          [[ 6.6610e-02,  3.4874e-02, -6.2876e-02],\n",
       "           [-9.7880e-02, -7.8525e-02,  1.3208e-02],\n",
       "           [ 2.1194e-02,  2.0184e-02,  4.7626e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.5977e-02,  2.4274e-04, -7.3659e-02],\n",
       "           [ 3.4955e-02,  2.0766e-04, -6.6353e-02],\n",
       "           [-3.0635e-02, -8.9212e-02, -8.0369e-02]],\n",
       " \n",
       "          [[ 3.5458e-02,  5.0691e-02,  5.6356e-02],\n",
       "           [-6.9507e-02, -7.8763e-02,  5.6300e-02],\n",
       "           [-7.8542e-02,  4.8573e-02,  4.2874e-02]],\n",
       " \n",
       "          [[ 7.8197e-02, -2.5547e-02,  6.9443e-02],\n",
       "           [ 3.3932e-02,  4.2833e-02,  3.9080e-02],\n",
       "           [ 9.5562e-03,  3.1804e-02, -3.5910e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 8.5844e-02,  1.0267e-02,  3.7576e-02],\n",
       "           [-6.4400e-02,  1.7999e-02,  5.7669e-02],\n",
       "           [-5.2936e-02,  1.2189e-02, -2.9702e-02]],\n",
       " \n",
       "          [[-1.5719e-02,  2.3003e-02, -5.5228e-02],\n",
       "           [ 1.3512e-02, -4.3657e-02, -6.5158e-02],\n",
       "           [-8.7429e-02,  4.1937e-02, -8.9403e-02]],\n",
       " \n",
       "          [[-9.6481e-02, -1.1161e-01,  4.3303e-03],\n",
       "           [ 4.3951e-02,  3.3650e-02, -9.6000e-03],\n",
       "           [-1.6374e-02, -5.4969e-02, -1.5391e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7996e-02,  6.1581e-02,  2.5473e-02],\n",
       "           [-3.5922e-02, -6.9180e-02, -2.5360e-03],\n",
       "           [ 4.9582e-03, -1.4765e-02, -2.6379e-02]],\n",
       " \n",
       "          [[-1.7616e-02,  5.8505e-02,  3.7988e-02],\n",
       "           [ 2.0782e-02, -1.0724e-02, -5.6108e-02],\n",
       "           [-1.3121e-02,  4.5701e-02,  2.1855e-02]],\n",
       " \n",
       "          [[ 3.4417e-02,  4.5523e-02,  6.8021e-04],\n",
       "           [-7.4967e-02, -2.5214e-02,  6.5900e-02],\n",
       "           [-1.0105e-02, -2.2873e-02, -6.0953e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-3.4523e-02,  6.6768e-02,  2.7745e-03],\n",
       "           [ 8.1162e-03,  5.9099e-02, -9.5555e-03],\n",
       "           [ 8.0560e-02,  8.0643e-02, -4.9513e-02]],\n",
       " \n",
       "          [[ 4.0553e-02,  6.7749e-02, -4.4120e-03],\n",
       "           [ 3.9468e-03, -6.8770e-02, -3.0895e-02],\n",
       "           [ 2.2725e-02,  5.0807e-03,  4.3364e-02]],\n",
       " \n",
       "          [[-2.4738e-02, -4.3634e-02, -8.3669e-02],\n",
       "           [ 5.4237e-03, -6.4233e-02,  6.4105e-02],\n",
       "           [ 6.7278e-02,  1.3645e-02, -4.3164e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.4896e-02,  3.0747e-02,  7.3099e-02],\n",
       "           [-1.2115e-02, -5.2770e-02,  2.5867e-02],\n",
       "           [-4.7809e-02, -3.2854e-02, -2.5279e-03]],\n",
       " \n",
       "          [[-5.3709e-02, -3.7660e-02, -5.9531e-02],\n",
       "           [ 6.3313e-02,  1.4710e-02, -6.4579e-02],\n",
       "           [-3.1895e-03, -1.8423e-02,  4.1672e-02]],\n",
       " \n",
       "          [[-9.4873e-04, -6.4957e-02,  2.7637e-02],\n",
       "           [-6.2800e-02, -4.1095e-03, -3.3884e-02],\n",
       "           [-2.5281e-02,  4.3751e-02, -4.8496e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.7386e-02, -6.6542e-02, -1.2205e-02],\n",
       "           [ 6.7392e-02, -5.2789e-02,  2.7350e-02],\n",
       "           [ 6.0864e-02, -6.4452e-02,  3.7107e-02]],\n",
       " \n",
       "          [[ 3.7759e-02,  2.7698e-02,  1.5853e-03],\n",
       "           [-7.4981e-02,  3.8604e-02,  4.5300e-02],\n",
       "           [ 5.1756e-02, -1.0192e-02,  6.7167e-02]],\n",
       " \n",
       "          [[ 1.7298e-02, -5.4504e-02, -5.8358e-02],\n",
       "           [-7.2207e-02,  6.2963e-02,  1.7454e-02],\n",
       "           [-2.4614e-02,  6.3158e-02, -7.1191e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.0215e-04,  3.0667e-02,  7.8317e-02],\n",
       "           [ 2.2948e-02, -7.6227e-02, -3.3833e-02],\n",
       "           [ 3.5922e-02, -5.1528e-02, -6.2068e-02]],\n",
       " \n",
       "          [[-5.6861e-02,  5.3142e-02, -7.2646e-02],\n",
       "           [-4.7779e-02,  3.9082e-02,  6.8033e-02],\n",
       "           [-6.3109e-02,  6.2130e-03, -7.0543e-02]],\n",
       " \n",
       "          [[ 2.8451e-02, -1.0164e-02, -4.1189e-02],\n",
       "           [ 7.0239e-02,  4.5513e-02, -1.5442e-02],\n",
       "           [-1.8168e-02,  2.3263e-02, -4.7084e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.6876e-02,  7.6602e-02,  8.1817e-02],\n",
       "           [-7.4582e-03, -4.8869e-02, -3.7401e-02],\n",
       "           [-2.5936e-02, -1.9979e-02,  6.1309e-03]],\n",
       " \n",
       "          [[-9.0617e-03,  5.2115e-02,  4.9435e-03],\n",
       "           [ 4.8020e-02,  5.6860e-02,  6.6665e-02],\n",
       "           [ 3.4707e-02, -5.7225e-02,  1.7624e-02]],\n",
       " \n",
       "          [[ 6.6180e-02, -5.8437e-02,  5.6731e-02],\n",
       "           [ 5.0927e-02, -1.5015e-02, -1.0509e-02],\n",
       "           [ 1.6691e-02, -2.2969e-02, -5.8314e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.2011e-02,  4.0895e-03, -7.9280e-02],\n",
       "           [ 3.4530e-02, -6.0182e-02, -4.9738e-02],\n",
       "           [ 2.4144e-02,  7.6632e-02, -1.4648e-02]],\n",
       " \n",
       "          [[-4.7271e-02,  1.8817e-02,  2.3256e-02],\n",
       "           [ 4.7761e-02, -2.6601e-02, -3.2683e-02],\n",
       "           [ 4.3688e-02, -7.7047e-02, -7.0671e-02]],\n",
       " \n",
       "          [[ 7.3427e-02, -1.8919e-02, -4.4701e-02],\n",
       "           [-4.6445e-02,  1.1777e-02,  3.9449e-02],\n",
       "           [ 4.8348e-03,  1.9462e-02, -6.9584e-02]]]], requires_grad=True),\n",
       " 'conv3.bias': Parameter containing:\n",
       " tensor([ 0.0353,  0.0200, -0.0553,  0.0215, -0.0337,  0.0596, -0.0038, -0.0530,\n",
       "          0.0299, -0.0898, -0.0375,  0.0427, -0.0177,  0.0135, -0.0219,  0.0267,\n",
       "          0.0151, -0.0345, -0.0355,  0.0391, -0.0837,  0.0123, -0.0308, -0.0164,\n",
       "          0.0052,  0.0305,  0.0290, -0.0547, -0.0009,  0.0457, -0.0155,  0.0267],\n",
       "        requires_grad=True),\n",
       " 'bn3.weight': Parameter containing:\n",
       " tensor([0.9684, 0.9698, 0.9704, 0.9761, 0.9622, 0.9686, 0.9616, 0.9659, 0.9566,\n",
       "         0.9781, 0.9756, 0.9703, 0.9697, 0.9582, 0.9670, 0.9806, 0.9688, 0.9702,\n",
       "         0.9642, 0.9627, 0.9647, 0.9735, 0.9665, 0.9752, 0.9640, 0.9739, 0.9684,\n",
       "         0.9724, 0.9686, 0.9742, 0.9642, 0.9588], requires_grad=True),\n",
       " 'bn3.bias': Parameter containing:\n",
       " tensor([-0.0215, -0.0395, -0.0251, -0.0206, -0.0356, -0.0302, -0.0339, -0.0365,\n",
       "         -0.0360, -0.0241, -0.0276, -0.0254, -0.0305, -0.0283, -0.0400, -0.0254,\n",
       "         -0.0173, -0.0277, -0.0325, -0.0373, -0.0252, -0.0261, -0.0316, -0.0244,\n",
       "         -0.0431, -0.0255, -0.0309, -0.0291, -0.0239, -0.0284, -0.0257, -0.0380],\n",
       "        requires_grad=True),\n",
       " 'fc.weight': Parameter containing:\n",
       " tensor([[-5.2474e-04, -1.9844e-03,  1.9047e-03,  ..., -4.9189e-03,\n",
       "          -6.5951e-03, -1.3909e-03],\n",
       "         [-1.3321e-03, -4.6998e-04,  9.6205e-04,  ...,  5.2791e-05,\n",
       "           8.5300e-03,  4.8922e-04],\n",
       "         [ 1.0661e-03, -1.5482e-03, -2.1154e-04,  ...,  2.8708e-03,\n",
       "           7.4056e-03, -1.4000e-03]], requires_grad=True),\n",
       " 'fc.bias': Parameter containing:\n",
       " tensor([0.0013, 0.0005, 0.0021], requires_grad=True)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.get_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
