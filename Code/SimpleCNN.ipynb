{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.nn import Module,Sequential,Linear,Conv2d,BatchNorm2d,ReLU,MaxPool2d\n",
    "from torch.utils.data import DataLoader\n",
    "import pathlib\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=3):\n",
    "        #giving default number of classes as 3\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Input shape= (batch_size,3,150,150)\n",
    "        # batch_size images in a batch x 3 channels(r,g,b) in an image x (150*150) pixels in an image.\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Applies 12 different filters and therefore obtains 12 different activation maps for all images in the btatch so only depth is changed\n",
    "        #Shape= (batch_size,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Number of features is only fed as the batchnorm input\n",
    "        #Shape= (batch_size,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (batch_size,12,150,150)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (batch_size,12,75,75)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (batch_size,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (batch_size,20,75,75)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (batch_size,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (batch_size,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (batch_size,32,75,75)\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Feed forwad function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "        #Above output will be in matrix form, with shape (batch_size,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "        #C-1 inferrs values from other dimensions to ensure the final dimension is equla to the previous end multiplication result(batch_size,32,75,75)\n",
    "        #batch_size entries with each entry as a single arra flattened from previous matrices . Each array length = 32*75*75\n",
    "            \n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(150),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes to be made in below cell :\n",
    "\n",
    "Make a way to slice the dataset for each client\n",
    "Compile everything to one single class\n",
    "So, take number of data samples and batch size as an input to the model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = '/Users/tarunvisvar/Downloads/Dataset/Handwriting/Handwriting-subset/Train'\n",
    "test_path = '/Users/tarunvisvar/Downloads/Dataset/Handwriting/Handwriting-subset/Test'\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform = preprocess),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform = preprocess),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pathlib.Path(train_path)\n",
    "classes = [dir.name for dir in root.iterdir()]\n",
    "classes.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reversal', 'Normal', 'Corrected']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes = 3)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the size of training and testing images\n",
    "import glob\n",
    "train_count=len(glob.glob(train_path+'/**/*.png'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1040)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count,test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/tarunvisvar/Downloads/SimpleCNN.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# The images(in batches) are preprocessed while brought up by the trainloader itself\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# The images(in batches) are passed through various layers and predictions are made.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Those are the outputs and are compared with the labels\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# The output is a batch_size length vector containing predicted output for batch_size images\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func(outputs,labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward() \u001b[39m# backpropagation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep() \u001b[39m# Updates the weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#print(\"loss.data = \",loss.data)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# For each image, we must add the loss to training loss. But loss is given for a batch by the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# So, we take the loss for a batch and multiply it with the batch size to get the loss for each image in an approximate manner\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "     model.train()\n",
    "     #Model will be in training mode and takes place on training dataset\n",
    "     train_loss = 0.0\n",
    "     train_accuracy = 0.0\n",
    "     for images,labels in train_loader:\n",
    "          # The loop runs for 'number of batches' times \n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(images) \n",
    "          # The images(in batches) are preprocessed while brought up by the trainloader itself\n",
    "          # The images(in batches) are passed through various layers and predictions are made.\n",
    "          # Those are the outputs and are compared with the labels\n",
    "          # The output is a batch_size length vector containing predicted output for batch_size images\n",
    "\n",
    "          loss = loss_func(outputs,labels)\n",
    "          loss.backward() # backpropagation\n",
    "          optimizer.step() # Updates the weights\n",
    "          #print(\"loss.data = \",loss.data)\n",
    "          \n",
    "          # For each image, we must add the loss to training loss. But loss is given for a batch by the model\n",
    "          # So, we take the loss for a batch and multiply it with the batch size to get the loss for each image in an approximate manner\n",
    "\n",
    "          train_loss += loss.data*batch_size\n",
    "          #print(outputs.data) #outputs will be of size 10 x 3, for 10 images in a batch and 3 predictions for each image in a batch\n",
    "          _,predictions = torch.max(outputs.data,1)\n",
    "          #print(predictions) #predictions will contain the indices of the highest value outputed for each image. Therefore, predictions will contain 10(batch_size) values of the indices(hence also the classes)\n",
    "          train_accuracy+=int(torch.sum(predictions==labels.data))\n",
    "     train_accuracy /= train_count\n",
    "     train_loss /= train_count\n",
    "     print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy))\n",
    "     model.eval()\n",
    "     #Modle will eb in the mode on evaluating on test dataset\n",
    "     test_accuracy = 0.0\n",
    "     for images,labels in test_loader:\n",
    "          outputs = model(images)\n",
    "          _,predictions = torch.max(outputs.data,1)\n",
    "          #print(outputs.data)\n",
    "          test_accuracy += int(torch.sum(predictions==labels.data))\n",
    "     test_accuracy /= test_count\n",
    "     print(\"Test accuracy =  \",str(test_accuracy))\n",
    "     if test_accuracy>best_accuracy:\n",
    "        torch.save(model,'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9548076923076924\n"
     ]
    }
   ],
   "source": [
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load('best_checkpoint.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight Parameter containing:\n",
      "tensor([[[[-0.0798,  0.1037, -0.0650],\n",
      "          [-0.1469, -0.0271, -0.0710],\n",
      "          [ 0.0055, -0.1653,  0.1933]],\n",
      "\n",
      "         [[-0.1393,  0.0436, -0.0150],\n",
      "          [-0.0965, -0.0228, -0.0916],\n",
      "          [-0.0106, -0.0282,  0.0208]],\n",
      "\n",
      "         [[-0.1845,  0.0477,  0.1889],\n",
      "          [ 0.0841,  0.1630,  0.1174],\n",
      "          [-0.0038,  0.1136, -0.1315]]],\n",
      "\n",
      "\n",
      "        [[[-0.0660, -0.0337, -0.1542],\n",
      "          [-0.1738, -0.0893,  0.0488],\n",
      "          [-0.0170, -0.1456, -0.0249]],\n",
      "\n",
      "         [[ 0.0316,  0.0687,  0.1745],\n",
      "          [-0.1044,  0.1226,  0.1334],\n",
      "          [ 0.0947, -0.0266, -0.0758]],\n",
      "\n",
      "         [[-0.1096, -0.0644,  0.1631],\n",
      "          [-0.0897, -0.0504, -0.1465],\n",
      "          [-0.2277, -0.0462, -0.1048]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0362, -0.0673, -0.1224],\n",
      "          [ 0.1730, -0.0061, -0.1046],\n",
      "          [-0.1686,  0.0575, -0.0285]],\n",
      "\n",
      "         [[ 0.1916,  0.0630, -0.1797],\n",
      "          [ 0.0075,  0.0879, -0.0115],\n",
      "          [ 0.1452, -0.0021,  0.0287]],\n",
      "\n",
      "         [[ 0.1965, -0.1049, -0.1007],\n",
      "          [-0.0998,  0.0963,  0.0776],\n",
      "          [ 0.1219, -0.0937, -0.1701]]],\n",
      "\n",
      "\n",
      "        [[[-0.1245, -0.1916, -0.1136],\n",
      "          [-0.0667, -0.1148,  0.1505],\n",
      "          [-0.1050,  0.0130,  0.1876]],\n",
      "\n",
      "         [[ 0.1079, -0.0485, -0.1661],\n",
      "          [ 0.1335,  0.0579,  0.0667],\n",
      "          [ 0.1631,  0.1537,  0.1758]],\n",
      "\n",
      "         [[ 0.0680,  0.0486, -0.0123],\n",
      "          [ 0.0852,  0.1067,  0.1821],\n",
      "          [ 0.1722, -0.0371,  0.1240]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0751, -0.0367,  0.0088],\n",
      "          [-0.1362,  0.0198,  0.1079],\n",
      "          [ 0.0053,  0.0632,  0.0123]],\n",
      "\n",
      "         [[-0.0688, -0.1451, -0.1058],\n",
      "          [ 0.0238, -0.0126, -0.0108],\n",
      "          [ 0.1096,  0.0588,  0.0729]],\n",
      "\n",
      "         [[-0.0756, -0.0781, -0.1848],\n",
      "          [ 0.1798,  0.0349, -0.0838],\n",
      "          [-0.0944,  0.0610,  0.1409]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1538, -0.0918, -0.1600],\n",
      "          [-0.1337, -0.0477,  0.1340],\n",
      "          [-0.1088,  0.1302, -0.0423]],\n",
      "\n",
      "         [[ 0.0208,  0.0596,  0.0695],\n",
      "          [-0.1874, -0.0105, -0.1406],\n",
      "          [-0.0916, -0.1145, -0.0830]],\n",
      "\n",
      "         [[ 0.1070,  0.1266,  0.0411],\n",
      "          [-0.0954,  0.0371, -0.0943],\n",
      "          [ 0.0101, -0.0192, -0.0152]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0635,  0.1612,  0.0505],\n",
      "          [-0.0471,  0.1586,  0.0335],\n",
      "          [-0.1935, -0.0531,  0.1269]],\n",
      "\n",
      "         [[ 0.0130, -0.1216,  0.0930],\n",
      "          [ 0.1254, -0.1761, -0.1889],\n",
      "          [ 0.1364,  0.1576,  0.0809]],\n",
      "\n",
      "         [[ 0.0343, -0.0253,  0.0140],\n",
      "          [-0.1776,  0.0810,  0.0514],\n",
      "          [ 0.0317, -0.0467,  0.0403]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0568, -0.1332,  0.1599],\n",
      "          [ 0.1280, -0.1556,  0.0289],\n",
      "          [-0.0185, -0.0851,  0.1838]],\n",
      "\n",
      "         [[ 0.1825, -0.0269, -0.1852],\n",
      "          [-0.0335,  0.0972,  0.0600],\n",
      "          [ 0.0735,  0.1065, -0.0982]],\n",
      "\n",
      "         [[ 0.0952, -0.1833, -0.1784],\n",
      "          [-0.0643,  0.1014, -0.0734],\n",
      "          [ 0.1112,  0.1556, -0.0703]]],\n",
      "\n",
      "\n",
      "        [[[-0.0870,  0.1634,  0.0581],\n",
      "          [ 0.0443, -0.1432,  0.1911],\n",
      "          [ 0.1633, -0.1411,  0.0798]],\n",
      "\n",
      "         [[ 0.0441, -0.0815,  0.0375],\n",
      "          [ 0.1486, -0.1656, -0.0641],\n",
      "          [ 0.1327,  0.1087,  0.1785]],\n",
      "\n",
      "         [[-0.1884, -0.1639, -0.0007],\n",
      "          [-0.0458,  0.0199,  0.1482],\n",
      "          [-0.1150,  0.1042, -0.1309]]],\n",
      "\n",
      "\n",
      "        [[[-0.1522, -0.1958, -0.1266],\n",
      "          [ 0.0510, -0.1174,  0.0716],\n",
      "          [ 0.0413, -0.1612,  0.1684]],\n",
      "\n",
      "         [[ 0.1293,  0.1614, -0.1751],\n",
      "          [ 0.1188, -0.1938,  0.0313],\n",
      "          [-0.0910,  0.1451, -0.1276]],\n",
      "\n",
      "         [[-0.1259, -0.0701, -0.1574],\n",
      "          [-0.1177, -0.1581,  0.0148],\n",
      "          [ 0.1299,  0.1686, -0.1155]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0581, -0.1714, -0.0903],\n",
      "          [ 0.0260, -0.1778, -0.0246],\n",
      "          [ 0.0729, -0.1597,  0.1831]],\n",
      "\n",
      "         [[ 0.1082,  0.1880, -0.1874],\n",
      "          [ 0.0286, -0.1439,  0.0965],\n",
      "          [-0.0122, -0.1227,  0.0440]],\n",
      "\n",
      "         [[ 0.0511,  0.0631,  0.1716],\n",
      "          [ 0.1594, -0.1143,  0.1428],\n",
      "          [ 0.1319,  0.0713,  0.0318]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0786, -0.1691, -0.1824],\n",
      "          [ 0.1993, -0.1850,  0.1166],\n",
      "          [-0.0638,  0.1079,  0.0834]],\n",
      "\n",
      "         [[ 0.1124,  0.1083,  0.0253],\n",
      "          [ 0.1308, -0.0418,  0.1543],\n",
      "          [-0.1664,  0.0500, -0.0988]],\n",
      "\n",
      "         [[-0.0148, -0.0939, -0.0882],\n",
      "          [ 0.1171,  0.0878,  0.1325],\n",
      "          [-0.0855, -0.0691, -0.0475]]]], requires_grad=True)\n",
      "conv1.bias Parameter containing:\n",
      "tensor([ 0.0102, -0.0696,  0.1525, -0.0433, -0.0668,  0.2225,  0.0032, -0.0186,\n",
      "         0.1248, -0.0308,  0.0862,  0.1895], requires_grad=True)\n",
      "bn1.weight Parameter containing:\n",
      "tensor([0.9994, 0.9993, 1.0228, 0.9983, 1.0157, 0.9928, 0.9963, 0.9974, 1.0051,\n",
      "        1.0021, 0.9844, 0.9886], requires_grad=True)\n",
      "bn1.bias Parameter containing:\n",
      "tensor([-0.0040,  0.0020, -0.0103, -0.0077,  0.0036, -0.0069, -0.0051, -0.0165,\n",
      "         0.0004,  0.0021, -0.0169, -0.0110], requires_grad=True)\n",
      "conv2.weight Parameter containing:\n",
      "tensor([[[[ 4.0014e-02, -5.5907e-02, -4.7229e-02],\n",
      "          [ 3.7686e-02, -3.2202e-02, -4.9195e-02],\n",
      "          [-7.9502e-02,  3.3697e-02, -4.6560e-02]],\n",
      "\n",
      "         [[ 3.9590e-02,  6.3127e-02,  6.1443e-02],\n",
      "          [-2.5887e-02, -1.2072e-02,  4.4082e-02],\n",
      "          [ 9.7406e-02,  7.7237e-02, -6.1352e-02]],\n",
      "\n",
      "         [[ 1.8543e-02, -9.9208e-02,  4.3228e-02],\n",
      "          [ 8.5202e-02, -6.4505e-03,  7.3152e-04],\n",
      "          [-4.0173e-02, -1.0298e-01,  7.9007e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.1851e-03, -7.1553e-02,  3.1610e-02],\n",
      "          [ 9.5946e-03,  2.0583e-02,  5.0493e-02],\n",
      "          [ 7.9969e-02,  1.0133e-01, -1.6662e-02]],\n",
      "\n",
      "         [[-3.9032e-02,  8.1860e-03,  7.1965e-02],\n",
      "          [-8.3357e-02,  7.5778e-02, -3.1367e-02],\n",
      "          [ 2.7208e-02, -1.9181e-02,  1.8413e-02]],\n",
      "\n",
      "         [[-9.1687e-02,  3.2724e-02, -2.8693e-03],\n",
      "          [ 5.0501e-03,  6.9578e-02, -1.8146e-02],\n",
      "          [ 4.3686e-02, -8.4151e-02, -6.2055e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5848e-02, -3.6793e-02, -4.1897e-02],\n",
      "          [-3.7775e-02,  2.5838e-02, -1.9028e-02],\n",
      "          [ 9.6510e-02, -7.8926e-02, -4.6590e-02]],\n",
      "\n",
      "         [[ 4.8535e-04, -1.7070e-02, -4.8887e-02],\n",
      "          [-5.2385e-02,  8.0104e-02,  6.5797e-02],\n",
      "          [ 1.6331e-02, -3.3751e-02,  1.2906e-02]],\n",
      "\n",
      "         [[-6.0361e-02, -5.1931e-02,  2.5622e-02],\n",
      "          [-9.8923e-03, -9.6130e-02,  8.8825e-02],\n",
      "          [ 8.6655e-02, -6.4556e-02,  2.6739e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.2051e-02, -2.0556e-02,  2.1916e-02],\n",
      "          [ 6.7402e-02,  5.3403e-02, -4.0664e-02],\n",
      "          [-3.1700e-02, -9.7505e-02,  3.2620e-02]],\n",
      "\n",
      "         [[ 1.0415e-01, -7.8946e-03, -1.0836e-02],\n",
      "          [-1.5064e-02,  7.6456e-02,  3.1564e-02],\n",
      "          [ 6.4166e-02, -3.9850e-02, -8.6927e-02]],\n",
      "\n",
      "         [[-4.8404e-02, -4.4930e-02,  8.2415e-02],\n",
      "          [-4.0944e-02,  3.4353e-02, -6.4601e-02],\n",
      "          [-3.1645e-03, -4.5144e-02,  4.9301e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6815e-02,  7.4193e-02,  2.0107e-02],\n",
      "          [-7.7793e-02, -4.8804e-02, -6.9463e-02],\n",
      "          [-6.7753e-02, -8.6936e-03, -1.0261e-02]],\n",
      "\n",
      "         [[ 3.7053e-02, -6.1070e-02,  5.9091e-02],\n",
      "          [-6.2052e-02, -1.8786e-02, -4.3860e-02],\n",
      "          [-3.1068e-02,  5.0248e-02,  9.0199e-02]],\n",
      "\n",
      "         [[-5.8770e-02, -5.1050e-02,  5.3379e-04],\n",
      "          [-3.8115e-02,  9.6788e-02,  4.7690e-02],\n",
      "          [-5.7355e-02,  5.5398e-03,  4.2280e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.2531e-02, -1.6631e-03, -9.5985e-02],\n",
      "          [-8.4051e-02,  6.7124e-02, -6.5893e-02],\n",
      "          [-1.7191e-02, -5.0920e-02, -5.3902e-03]],\n",
      "\n",
      "         [[-2.4229e-02,  4.3639e-02,  4.4766e-02],\n",
      "          [ 5.2287e-02, -1.7356e-02, -6.4244e-02],\n",
      "          [ 7.1957e-02, -4.8848e-02, -3.0468e-02]],\n",
      "\n",
      "         [[-9.6967e-02, -5.3787e-03,  2.4352e-02],\n",
      "          [ 5.2886e-02, -9.5142e-02, -4.3429e-02],\n",
      "          [-3.5549e-04,  4.5962e-02,  5.6549e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.2081e-02, -3.7568e-03,  2.5743e-02],\n",
      "          [ 4.0097e-02, -2.9460e-02,  2.6921e-02],\n",
      "          [ 1.2736e-02, -9.6810e-02,  3.2613e-02]],\n",
      "\n",
      "         [[-5.3341e-02,  2.5703e-03, -4.8784e-02],\n",
      "          [-2.1082e-02, -3.6177e-02,  3.8055e-02],\n",
      "          [-8.4561e-03,  4.9198e-02,  2.6666e-02]],\n",
      "\n",
      "         [[-1.0107e-01,  1.0222e-01,  4.3661e-02],\n",
      "          [-2.0441e-02,  9.0584e-02, -2.7187e-02],\n",
      "          [ 9.0540e-02,  1.0529e-01,  3.6167e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4996e-02,  2.5198e-02,  1.2151e-02],\n",
      "          [-4.3673e-02,  4.2069e-02,  4.7992e-02],\n",
      "          [ 5.1513e-03,  3.5167e-02,  1.6683e-02]],\n",
      "\n",
      "         [[-1.7889e-02,  6.0844e-02, -6.8696e-02],\n",
      "          [-2.2730e-02, -6.5304e-02, -8.2923e-02],\n",
      "          [-6.4870e-02, -2.3228e-02,  6.3641e-02]],\n",
      "\n",
      "         [[ 2.8828e-02,  6.7765e-02,  3.3898e-02],\n",
      "          [-6.6438e-02,  6.0304e-02, -8.6538e-02],\n",
      "          [-3.8728e-02,  8.2313e-02, -7.8175e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1538e-02, -7.9705e-03, -8.5056e-02],\n",
      "          [ 1.4047e-02, -9.7171e-02,  2.8431e-02],\n",
      "          [-8.5600e-02, -8.9397e-02,  3.9190e-02]],\n",
      "\n",
      "         [[ 5.5769e-02, -1.0290e-01,  1.1030e-02],\n",
      "          [-8.7339e-02,  6.6383e-02, -6.9731e-02],\n",
      "          [-4.4090e-02,  8.6868e-02,  1.4887e-02]],\n",
      "\n",
      "         [[ 6.9374e-02,  8.8109e-02,  7.9316e-02],\n",
      "          [-3.1610e-02, -6.9688e-02, -2.5596e-02],\n",
      "          [-5.0338e-02,  4.4092e-02, -1.8360e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.5870e-02, -8.0691e-02,  2.6138e-02],\n",
      "          [-3.3486e-02, -6.1911e-02, -1.9850e-02],\n",
      "          [-7.1353e-02,  1.4922e-02,  9.1242e-02]],\n",
      "\n",
      "         [[-4.0473e-02,  4.3822e-02, -1.0439e-01],\n",
      "          [ 2.0997e-03, -5.6579e-02, -4.1202e-02],\n",
      "          [ 4.5802e-02,  7.3890e-02,  8.1858e-02]],\n",
      "\n",
      "         [[-3.6663e-02, -9.7967e-02,  4.1897e-02],\n",
      "          [-6.7361e-02, -4.3654e-02, -8.9695e-02],\n",
      "          [-2.6478e-02,  2.5847e-02,  4.1467e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.2517e-02,  6.7993e-02,  3.5096e-02],\n",
      "          [ 2.8533e-03,  4.4402e-02, -3.1966e-02],\n",
      "          [-4.4770e-02,  2.9729e-02,  5.6516e-02]],\n",
      "\n",
      "         [[-2.6635e-02,  3.2937e-02,  3.9592e-02],\n",
      "          [-5.2866e-02,  1.5523e-02, -2.5416e-03],\n",
      "          [-1.2683e-02, -2.4462e-06, -9.0621e-02]],\n",
      "\n",
      "         [[-4.5831e-02, -6.7809e-02,  3.6842e-02],\n",
      "          [ 2.3329e-02,  9.3146e-03,  8.2909e-03],\n",
      "          [-8.2940e-02,  7.4213e-03, -6.9778e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.2988e-02, -4.6735e-02, -9.1570e-03],\n",
      "          [-3.0574e-02,  1.1746e-02,  1.2461e-02],\n",
      "          [-6.7488e-02, -6.6005e-02,  5.3716e-02]],\n",
      "\n",
      "         [[-2.4264e-02,  5.7186e-02, -6.4715e-02],\n",
      "          [-2.3766e-03,  1.9511e-02,  3.0709e-02],\n",
      "          [ 7.3509e-02, -2.1162e-03,  2.9385e-02]],\n",
      "\n",
      "         [[ 5.6059e-03,  2.4087e-02, -9.2260e-02],\n",
      "          [-7.1294e-02, -5.6747e-02, -7.1963e-02],\n",
      "          [-2.7150e-02,  1.1582e-02, -5.2399e-02]]]], requires_grad=True)\n",
      "conv2.bias Parameter containing:\n",
      "tensor([ 0.0530,  0.0346, -0.0375,  0.0596,  0.0410,  0.0490, -0.0820, -0.0820,\n",
      "        -0.0070, -0.0612, -0.0341, -0.0140,  0.0157,  0.0541,  0.0708, -0.0748,\n",
      "        -0.1023,  0.0604, -0.0005, -0.0665], requires_grad=True)\n",
      "conv3.weight Parameter containing:\n",
      "tensor([[[[ 5.8768e-02,  4.6348e-02,  1.9402e-02],\n",
      "          [ 4.8711e-02, -6.4123e-02, -3.9725e-02],\n",
      "          [ 3.3096e-02,  4.4966e-02,  2.9698e-03]],\n",
      "\n",
      "         [[ 4.3877e-02, -4.3724e-02,  2.6226e-02],\n",
      "          [-2.8318e-02, -4.6192e-02, -6.7605e-02],\n",
      "          [ 5.7979e-02,  1.9868e-02,  6.7468e-02]],\n",
      "\n",
      "         [[ 2.4604e-02, -2.7938e-03, -1.8175e-04],\n",
      "          [ 9.6448e-03,  4.9602e-02, -5.4484e-02],\n",
      "          [ 5.0274e-03,  6.3861e-02, -1.0053e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.4225e-02,  4.4866e-02,  3.9001e-02],\n",
      "          [-4.6630e-02, -6.3058e-02, -1.2914e-02],\n",
      "          [-6.9772e-02,  4.0487e-02, -8.6407e-03]],\n",
      "\n",
      "         [[-4.8353e-03, -5.9133e-02,  7.0127e-02],\n",
      "          [ 7.9317e-02,  6.8664e-03, -3.6274e-02],\n",
      "          [ 2.5016e-02, -3.3031e-02,  2.3384e-02]],\n",
      "\n",
      "         [[-5.6836e-02,  1.1937e-02, -7.0425e-02],\n",
      "          [-5.2147e-02,  7.6755e-02, -6.6607e-02],\n",
      "          [-1.1042e-02,  2.5939e-02, -1.1333e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5583e-02,  1.8841e-03,  6.8440e-02],\n",
      "          [ 6.9559e-02, -2.6320e-02, -7.1257e-02],\n",
      "          [-1.1573e-02,  1.0971e-02, -6.7598e-02]],\n",
      "\n",
      "         [[ 4.1140e-02, -1.9844e-02, -3.2464e-02],\n",
      "          [ 5.4037e-02,  4.2152e-02, -4.2910e-02],\n",
      "          [ 3.0023e-02, -3.2751e-02, -6.1222e-02]],\n",
      "\n",
      "         [[ 5.0119e-02, -2.6062e-02,  3.5857e-03],\n",
      "          [-5.6689e-02, -1.2678e-03, -5.9231e-02],\n",
      "          [ 5.9172e-02, -5.4227e-02,  5.7556e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.9744e-02, -6.3371e-03,  1.6208e-02],\n",
      "          [ 5.0217e-02,  1.4678e-02,  4.4197e-02],\n",
      "          [-8.7023e-02, -2.1387e-04,  1.4466e-02]],\n",
      "\n",
      "         [[ 3.9643e-02,  1.0173e-02, -5.2133e-02],\n",
      "          [-7.9631e-04, -3.0386e-02, -5.1320e-02],\n",
      "          [-1.5129e-03,  5.6429e-02,  9.9730e-06]],\n",
      "\n",
      "         [[-1.5501e-02,  5.3026e-03,  1.5187e-02],\n",
      "          [ 2.5478e-02, -1.3840e-02, -9.6759e-03],\n",
      "          [ 2.8428e-02, -2.0493e-02,  5.7612e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9405e-02,  2.9650e-03,  6.9084e-02],\n",
      "          [ 5.1607e-02, -2.9666e-02,  2.6162e-02],\n",
      "          [ 2.8851e-02,  8.6062e-03, -5.1475e-02]],\n",
      "\n",
      "         [[-4.6584e-02,  7.2794e-02,  1.0452e-02],\n",
      "          [-4.9768e-02, -4.3058e-02,  8.3995e-03],\n",
      "          [ 3.5680e-02,  1.4734e-02, -5.5315e-02]],\n",
      "\n",
      "         [[-2.7227e-02, -1.3503e-02,  7.2727e-02],\n",
      "          [ 6.4138e-02, -5.2266e-02,  2.5863e-02],\n",
      "          [-1.0637e-02, -4.4244e-02, -3.5295e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0458e-02,  6.5645e-02,  2.7821e-02],\n",
      "          [ 3.9545e-02,  4.1241e-02, -7.3643e-03],\n",
      "          [-1.6440e-02, -4.3270e-02,  6.6836e-02]],\n",
      "\n",
      "         [[-5.7261e-03, -8.0287e-02, -2.1687e-02],\n",
      "          [-6.5756e-02, -1.6177e-02,  7.1230e-03],\n",
      "          [ 2.2212e-02,  1.7317e-02, -5.9337e-02]],\n",
      "\n",
      "         [[ 1.3828e-02,  6.3652e-02,  6.2417e-02],\n",
      "          [ 2.6576e-02,  7.5047e-02, -2.3257e-02],\n",
      "          [ 2.1249e-02,  4.0419e-02,  3.7228e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.7871e-02,  5.3776e-02, -4.3583e-02],\n",
      "          [-1.2317e-03,  4.6768e-02,  8.6352e-02],\n",
      "          [-6.8155e-03,  2.9449e-02, -2.3930e-02]],\n",
      "\n",
      "         [[-1.9980e-02, -4.6385e-03, -6.5755e-02],\n",
      "          [-5.2241e-02,  8.6790e-02, -1.7476e-02],\n",
      "          [-2.7716e-02,  1.6506e-02,  6.0822e-02]],\n",
      "\n",
      "         [[ 8.0907e-03, -5.5256e-02,  6.1960e-02],\n",
      "          [-6.5317e-02, -6.4178e-02, -3.6862e-02],\n",
      "          [-2.6606e-02,  7.9347e-02, -3.5404e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.0442e-03, -5.1557e-02, -8.7241e-02],\n",
      "          [-7.4869e-02,  8.8118e-03, -1.4581e-02],\n",
      "          [ 4.9349e-02, -6.6756e-02, -8.6974e-03]],\n",
      "\n",
      "         [[-1.6738e-02, -7.2266e-02, -7.1439e-02],\n",
      "          [-9.5045e-02,  3.2359e-02, -5.6952e-02],\n",
      "          [-4.2939e-02, -5.1918e-02,  2.0900e-02]],\n",
      "\n",
      "         [[-3.2462e-02, -5.7525e-03,  7.4101e-02],\n",
      "          [-4.3220e-02,  4.1990e-03,  1.2793e-02],\n",
      "          [ 1.1821e-02,  3.9770e-02, -3.9485e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5946e-02,  6.2104e-02, -6.9960e-02],\n",
      "          [ 1.7692e-02,  2.1686e-02,  2.6641e-02],\n",
      "          [-2.2806e-03,  4.8634e-02, -4.3703e-02]],\n",
      "\n",
      "         [[ 5.7415e-02, -6.5309e-02, -3.1582e-02],\n",
      "          [ 7.4620e-02,  9.9386e-03,  6.0929e-02],\n",
      "          [ 5.7852e-02,  2.7312e-02, -1.4519e-02]],\n",
      "\n",
      "         [[ 3.6185e-02, -7.9359e-02,  2.8882e-02],\n",
      "          [-3.9332e-02, -1.5036e-02, -4.7492e-02],\n",
      "          [-3.8086e-02, -3.1762e-02,  5.8735e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7856e-02, -5.4338e-02,  3.1341e-04],\n",
      "          [ 3.3256e-03, -7.7972e-02, -5.3165e-02],\n",
      "          [-5.3769e-02, -5.6653e-02, -9.1722e-03]],\n",
      "\n",
      "         [[ 2.9319e-02, -7.2626e-02,  2.4372e-02],\n",
      "          [ 6.0985e-02,  2.1953e-02,  3.0245e-02],\n",
      "          [-5.6439e-02, -7.7705e-02, -6.3417e-02]],\n",
      "\n",
      "         [[-1.6708e-02,  3.0227e-02,  5.4205e-02],\n",
      "          [ 4.3890e-02, -2.9756e-02, -4.9321e-02],\n",
      "          [ 5.6737e-02,  5.8462e-02, -5.2802e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3085e-02,  2.1328e-02,  6.6119e-03],\n",
      "          [ 5.7172e-02, -3.7995e-02,  6.5733e-02],\n",
      "          [-1.0740e-02,  8.1665e-02, -2.8091e-02]],\n",
      "\n",
      "         [[ 3.2684e-02, -3.8046e-04,  1.6736e-02],\n",
      "          [ 8.0149e-02,  8.7577e-02, -5.5938e-02],\n",
      "          [ 6.0829e-03,  6.2246e-02, -1.9501e-02]],\n",
      "\n",
      "         [[-2.8971e-02, -6.7100e-02, -4.4008e-02],\n",
      "          [ 6.0982e-02, -5.5980e-02, -7.0815e-03],\n",
      "          [ 2.3405e-02,  7.0315e-03,  3.3949e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9181e-02,  1.3925e-02, -1.0567e-02],\n",
      "          [ 2.8197e-02, -9.7303e-02, -4.5112e-02],\n",
      "          [-7.6210e-02, -8.0681e-02,  2.8850e-02]],\n",
      "\n",
      "         [[-3.5075e-02,  3.4495e-02,  4.3541e-03],\n",
      "          [ 8.8967e-03,  2.1912e-02,  5.5768e-02],\n",
      "          [-7.3845e-02,  4.2380e-02, -3.5851e-02]],\n",
      "\n",
      "         [[ 2.1222e-02, -4.6554e-02, -3.5413e-02],\n",
      "          [ 4.1669e-02, -3.9474e-02, -5.0681e-02],\n",
      "          [-5.4927e-02,  2.9206e-02,  5.5491e-02]]]], requires_grad=True)\n",
      "conv3.bias Parameter containing:\n",
      "tensor([-0.0774,  0.0344,  0.0224,  0.0801,  0.0181, -0.0757, -0.0586, -0.0582,\n",
      "         0.0407, -0.0749, -0.0518, -0.0704, -0.0644,  0.0255,  0.0310, -0.0626,\n",
      "        -0.0165,  0.0250,  0.0407,  0.0218, -0.0815, -0.0246,  0.0632, -0.0239,\n",
      "         0.0491, -0.0402, -0.0717,  0.0097, -0.0480, -0.0459,  0.0417, -0.0595],\n",
      "       requires_grad=True)\n",
      "bn3.weight Parameter containing:\n",
      "tensor([0.9610, 0.9567, 0.9516, 0.9652, 0.9701, 0.9673, 0.9733, 0.9830, 0.9726,\n",
      "        0.9732, 0.9713, 0.9624, 0.9721, 0.9717, 0.9666, 0.9678, 0.9642, 0.9624,\n",
      "        0.9735, 0.9710, 0.9680, 0.9535, 0.9755, 0.9667, 0.9602, 0.9705, 0.9633,\n",
      "        0.9511, 0.9650, 0.9732, 0.9713, 0.9735], requires_grad=True)\n",
      "bn3.bias Parameter containing:\n",
      "tensor([-0.0327, -0.0279, -0.0329, -0.0366, -0.0294, -0.0317, -0.0222, -0.0174,\n",
      "        -0.0194, -0.0166, -0.0340, -0.0241, -0.0279, -0.0213, -0.0336, -0.0258,\n",
      "        -0.0260, -0.0267, -0.0290, -0.0340, -0.0283, -0.0310, -0.0314, -0.0336,\n",
      "        -0.0384, -0.0242, -0.0271, -0.0216, -0.0272, -0.0284, -0.0222, -0.0247],\n",
      "       requires_grad=True)\n",
      "fc.weight Parameter containing:\n",
      "tensor([[ 6.4322e-03,  6.7801e-04,  1.1136e-03,  ..., -5.8722e-04,\n",
      "          1.8650e-03, -4.0424e-05],\n",
      "        [ 4.5394e-03, -1.1800e-03, -1.4925e-03,  ..., -2.2207e-04,\n",
      "         -7.1843e-04, -2.3499e-03],\n",
      "        [-4.4152e-03, -7.0845e-04, -1.2224e-03,  ..., -1.4006e-03,\n",
      "         -8.8566e-04,  1.1581e-03]], requires_grad=True)\n",
      "fc.bias Parameter containing:\n",
      "tensor([-0.0016, -0.0019,  0.0014], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name,param in loaded_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548399"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference:\n",
    "\n",
    "Number of parameters in a model = around 5 and half lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue development , try using inner classes \n",
    "class HWRModel:\n",
    "    def __init__(self,data_path,batch_size,local_data_count):\n",
    "        self.batch_size = batch_size\n",
    "        self.train_path = data_path + 'Train'\n",
    "        self.test_path = data_path + 'Test'\n",
    "        self.local_data_count = local_data_count # Amount of data that a user can choose \n",
    "    \n",
    "    def preprocess(self,resize=150):\n",
    "        transformer = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(resize),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "            ]\n",
    "        )\n",
    "        return transformer   \n",
    "\n",
    "    def get_model(self):\n",
    "        model = ConvNet(num_classes = 3)\n",
    "        optimizer = Adam(model.parameters(), lr=0.001)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        return (model,optimizer,loss_func)\n",
    "    \n",
    "    #Add load dataset function.\n",
    "\n",
    "    \n",
    "    def train(self,num_epochs=10):\n",
    "        model,optimizer,loss_func = self.get_model()\n",
    "        best_accuracy = 0.0\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            #Model will be in training mode and takes place on training dataset\n",
    "            train_loss = 0.0\n",
    "            train_accuracy = 0.0\n",
    "            for images,labels in train_loader:\n",
    "                # The loop runs for 'number of batches' times \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images) \n",
    "                # The images(in batches) are preprocessed while brought up by the trainloader itself\n",
    "                # The images(in batches) are passed through various layers and predictions are made.\n",
    "                # Those are the outputs and are compared with the labels\n",
    "                # The output is a batch_size length vector containing predicted output for batch_size images\n",
    "\n",
    "                loss = loss_func(outputs,labels)\n",
    "                loss.backward() # backpropagation\n",
    "                optimizer.step() # Updates the weights\n",
    "                #print(\"loss.data = \",loss.data)\n",
    "                \n",
    "                # For each image, we must add the loss to training loss. But loss is given for a batch by the model\n",
    "                # So, we take the loss for a batch and multiply it with the batch size to get the loss for each image in an approximate manner\n",
    "\n",
    "                train_loss += loss.data*batch_size\n",
    "                #print(outputs.data) #outputs will be of size 10 x 3, for 10 images in a batch and 3 predictions for each image in a batch\n",
    "                _,predictions = torch.max(outputs.data,1)\n",
    "                #print(predictions) #predictions will contain the indices of the highest value outputed for each image. Therefore, predictions will contain 10(batch_size) values of the indices(hence also the classes)\n",
    "                train_accuracy+=int(torch.sum(predictions==labels.data))\n",
    "            train_accuracy /= train_count\n",
    "            train_loss /= train_count\n",
    "            print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy))\n",
    "            model.eval()\n",
    "            #Modle will eb in the mode on evaluating on test dataset\n",
    "            test_accuracy = 0.0\n",
    "            for images,labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                _,predictions = torch.max(outputs.data,1)\n",
    "                #print(outputs.data)\n",
    "                test_accuracy += int(torch.sum(predictions==labels.data))\n",
    "            test_accuracy /= test_count\n",
    "            print(\"Test accuracy =  \",str(test_accuracy))\n",
    "            if test_accuracy>best_accuracy:\n",
    "                torch.save(model,'best_checkpoint.model')\n",
    "                best_accuracy=test_accuracy\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        loaded_model = torch.load('best_checkpoint.model')\n",
    "        params = dict()\n",
    "        for name,parameters in loaded_model.named_parameters():\n",
    "            params[name] = parameters\n",
    "        return params\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/tarunvisvar/Downloads/Dataset/Handwriting/Handwriting-subset'\n",
    "batch_size = 100\n",
    "local_data_count = 1000\n",
    "mymodel = HWRModel(data_path,batch_size,local_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/tarunvisvar/Downloads/SimpleCNN.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mymodel\u001b[39m.\u001b[39;49mtrain(num_epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32m/Users/tarunvisvar/Downloads/SimpleCNN.ipynb Cell 20\u001b[0m in \u001b[0;36mHWRModel.train\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X25sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X25sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m train_accuracy \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X25sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m images,labels \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X25sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# The loop runs for 'number of batches' times \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X25sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Downloads/SimpleCNN.ipynb#X25sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(images) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "mymodel.train(num_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1.weight': Parameter containing:\n",
       " tensor([[[[-0.1099, -0.1478,  0.0368],\n",
       "           [ 0.0878, -0.1387, -0.0547],\n",
       "           [ 0.0342,  0.0384, -0.1188]],\n",
       " \n",
       "          [[-0.0559, -0.0642, -0.1558],\n",
       "           [-0.0243,  0.0880, -0.0462],\n",
       "           [ 0.1699,  0.1450, -0.1700]],\n",
       " \n",
       "          [[-0.1284, -0.1713, -0.0907],\n",
       "           [ 0.1848, -0.1342,  0.1677],\n",
       "           [ 0.1138,  0.1677,  0.0939]]],\n",
       " \n",
       " \n",
       "         [[[-0.0175, -0.1370, -0.0860],\n",
       "           [ 0.1742, -0.1058, -0.0121],\n",
       "           [ 0.0410, -0.0942,  0.1959]],\n",
       " \n",
       "          [[-0.0349,  0.0510,  0.1600],\n",
       "           [ 0.1797, -0.0356, -0.0054],\n",
       "           [-0.1143,  0.0851,  0.0750]],\n",
       " \n",
       "          [[ 0.0190, -0.1036, -0.0170],\n",
       "           [ 0.0085, -0.1244,  0.1689],\n",
       "           [-0.0359, -0.1812, -0.1059]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1532, -0.1478,  0.0967],\n",
       "           [ 0.1412, -0.0112,  0.1796],\n",
       "           [ 0.1870,  0.1597,  0.1682]],\n",
       " \n",
       "          [[-0.1186, -0.0548,  0.1957],\n",
       "           [-0.1472, -0.0210, -0.0873],\n",
       "           [ 0.1612,  0.1722, -0.1332]],\n",
       " \n",
       "          [[-0.0050,  0.0279,  0.1198],\n",
       "           [ 0.1529,  0.1257, -0.1434],\n",
       "           [ 0.0242, -0.1430,  0.0398]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0232, -0.0284,  0.1442],\n",
       "           [-0.0679, -0.0139, -0.0091],\n",
       "           [ 0.0718,  0.0338,  0.0744]],\n",
       " \n",
       "          [[ 0.0695,  0.1074,  0.0843],\n",
       "           [-0.1595, -0.1784,  0.1068],\n",
       "           [-0.0094, -0.0040,  0.0561]],\n",
       " \n",
       "          [[-0.1926, -0.1230,  0.0709],\n",
       "           [-0.1219,  0.1116,  0.0924],\n",
       "           [-0.0344, -0.1617,  0.1589]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0501,  0.0182, -0.1031],\n",
       "           [-0.0903, -0.0114, -0.0177],\n",
       "           [ 0.0128, -0.0921, -0.1638]],\n",
       " \n",
       "          [[ 0.0906, -0.1214, -0.1142],\n",
       "           [ 0.0700,  0.1038, -0.1194],\n",
       "           [-0.1203, -0.1200, -0.1145]],\n",
       " \n",
       "          [[ 0.0104, -0.0084, -0.0738],\n",
       "           [-0.1756,  0.1407,  0.1196],\n",
       "           [ 0.1508, -0.0971, -0.0637]]],\n",
       " \n",
       " \n",
       "         [[[-0.0208, -0.1016, -0.0090],\n",
       "           [-0.0685, -0.0885,  0.0857],\n",
       "           [-0.1463,  0.0740,  0.1755]],\n",
       " \n",
       "          [[-0.0787,  0.1441,  0.0573],\n",
       "           [-0.1550, -0.0275, -0.0611],\n",
       "           [ 0.1237,  0.1327,  0.1484]],\n",
       " \n",
       "          [[ 0.0268,  0.1642, -0.1116],\n",
       "           [-0.1221,  0.1780, -0.0019],\n",
       "           [ 0.1727,  0.0665, -0.0901]]],\n",
       " \n",
       " \n",
       "         [[[-0.1734, -0.0654,  0.1023],\n",
       "           [-0.0741,  0.1350, -0.1393],\n",
       "           [ 0.1804, -0.1182,  0.1265]],\n",
       " \n",
       "          [[ 0.0129,  0.1501,  0.0197],\n",
       "           [ 0.0303,  0.0154, -0.1391],\n",
       "           [-0.1062,  0.0952, -0.0483]],\n",
       " \n",
       "          [[-0.1746, -0.0985,  0.0171],\n",
       "           [-0.0472,  0.1117,  0.1522],\n",
       "           [-0.1363,  0.0842, -0.0416]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0734,  0.0922, -0.0111],\n",
       "           [-0.1271, -0.0694, -0.0306],\n",
       "           [ 0.0552, -0.1968, -0.0071]],\n",
       " \n",
       "          [[-0.1542, -0.1518,  0.0383],\n",
       "           [ 0.0033, -0.1293, -0.1549],\n",
       "           [-0.0108, -0.2143, -0.1547]],\n",
       " \n",
       "          [[-0.0090, -0.0185,  0.1439],\n",
       "           [ 0.1600, -0.0419,  0.0900],\n",
       "           [ 0.0798, -0.1596, -0.0359]]],\n",
       " \n",
       " \n",
       "         [[[-0.1131,  0.0887,  0.1421],\n",
       "           [ 0.1782,  0.0177, -0.0667],\n",
       "           [-0.1108,  0.1103,  0.1102]],\n",
       " \n",
       "          [[-0.1680,  0.0264,  0.1705],\n",
       "           [-0.0135, -0.1136,  0.1678],\n",
       "           [ 0.1370, -0.0380,  0.1667]],\n",
       " \n",
       "          [[-0.0089,  0.1446, -0.0037],\n",
       "           [ 0.1545, -0.0540, -0.0545],\n",
       "           [-0.1464,  0.1825,  0.0038]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0689,  0.0413,  0.1830],\n",
       "           [-0.0730,  0.0291,  0.0732],\n",
       "           [ 0.0317,  0.1575,  0.0529]],\n",
       " \n",
       "          [[ 0.1128,  0.1794,  0.1105],\n",
       "           [ 0.0305,  0.0194, -0.1271],\n",
       "           [ 0.0544,  0.0232,  0.0945]],\n",
       " \n",
       "          [[-0.0221, -0.0217,  0.1734],\n",
       "           [ 0.1407,  0.1664, -0.1171],\n",
       "           [ 0.0413, -0.0562, -0.1509]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1768, -0.0517, -0.0412],\n",
       "           [-0.1154, -0.1259, -0.1517],\n",
       "           [ 0.1187,  0.0327,  0.0591]],\n",
       " \n",
       "          [[-0.0557,  0.1232, -0.0098],\n",
       "           [ 0.0173,  0.0278,  0.0969],\n",
       "           [ 0.1287, -0.0453,  0.1010]],\n",
       " \n",
       "          [[ 0.1950, -0.1095,  0.1319],\n",
       "           [ 0.1251,  0.0626, -0.1781],\n",
       "           [ 0.0778,  0.0800, -0.0714]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0037, -0.0758, -0.0708],\n",
       "           [-0.0705, -0.0126, -0.1368],\n",
       "           [-0.1044,  0.1172,  0.1413]],\n",
       " \n",
       "          [[ 0.1622, -0.1502, -0.0486],\n",
       "           [ 0.0053, -0.1481,  0.0169],\n",
       "           [ 0.0972, -0.0710,  0.0841]],\n",
       " \n",
       "          [[ 0.0176, -0.1104, -0.1620],\n",
       "           [-0.0186,  0.0137,  0.1153],\n",
       "           [-0.0148, -0.1984, -0.1516]]]], requires_grad=True),\n",
       " 'conv1.bias': Parameter containing:\n",
       " tensor([ 0.1426, -0.0137, -0.0239,  0.1489, -0.0867, -0.1344, -0.0113,  0.0644,\n",
       "          0.1612, -0.0881,  0.1501,  0.1131], requires_grad=True),\n",
       " 'bn1.weight': Parameter containing:\n",
       " tensor([1.0084, 1.0313, 0.9938, 1.0154, 0.9997, 0.9891, 1.0095, 1.0182, 0.9813,\n",
       "         0.9900, 0.9837, 1.0146], requires_grad=True),\n",
       " 'bn1.bias': Parameter containing:\n",
       " tensor([ 0.0065, -0.0012, -0.0193, -0.0016, -0.0005, -0.0140, -0.0022,  0.0203,\n",
       "         -0.0131, -0.0287, -0.0239,  0.0112], requires_grad=True),\n",
       " 'conv2.weight': Parameter containing:\n",
       " tensor([[[[-0.0277,  0.0365,  0.0932],\n",
       "           [ 0.0601, -0.0861,  0.0342],\n",
       "           [-0.0437,  0.0903,  0.0067]],\n",
       " \n",
       "          [[-0.0024, -0.0225,  0.0088],\n",
       "           [-0.0826,  0.0970,  0.0044],\n",
       "           [-0.0030,  0.0187,  0.0533]],\n",
       " \n",
       "          [[-0.0482,  0.0428, -0.1001],\n",
       "           [-0.0145, -0.0075,  0.0245],\n",
       "           [-0.0181, -0.0388, -0.0370]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0028,  0.0138,  0.0527],\n",
       "           [-0.0020, -0.0912,  0.0848],\n",
       "           [-0.1014,  0.0474,  0.0684]],\n",
       " \n",
       "          [[ 0.0765,  0.0031,  0.0582],\n",
       "           [-0.0995,  0.0587,  0.0150],\n",
       "           [-0.0533, -0.0260,  0.0736]],\n",
       " \n",
       "          [[-0.0504,  0.0828,  0.0120],\n",
       "           [ 0.0778,  0.0657, -0.0492],\n",
       "           [ 0.0351,  0.0649, -0.0730]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0159, -0.0569, -0.0341],\n",
       "           [ 0.0482, -0.0641, -0.0048],\n",
       "           [ 0.0209, -0.0824, -0.0183]],\n",
       " \n",
       "          [[-0.0248, -0.0178,  0.0486],\n",
       "           [ 0.0520, -0.0598,  0.0035],\n",
       "           [ 0.0744, -0.0057,  0.0794]],\n",
       " \n",
       "          [[ 0.0108,  0.0279,  0.0741],\n",
       "           [-0.0745,  0.0980, -0.0903],\n",
       "           [-0.0378, -0.0464, -0.0655]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0740, -0.0895, -0.0838],\n",
       "           [-0.0403,  0.0404,  0.0269],\n",
       "           [ 0.0484, -0.0427,  0.0243]],\n",
       " \n",
       "          [[ 0.0194, -0.0388,  0.0690],\n",
       "           [-0.0044,  0.0454,  0.0040],\n",
       "           [-0.0503,  0.0828, -0.0422]],\n",
       " \n",
       "          [[-0.0044,  0.0101,  0.0911],\n",
       "           [ 0.0852,  0.0329, -0.0292],\n",
       "           [-0.0929, -0.0096, -0.0884]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0868,  0.0557,  0.0640],\n",
       "           [-0.0061,  0.0869, -0.0045],\n",
       "           [ 0.0881,  0.0713,  0.0748]],\n",
       " \n",
       "          [[-0.0037,  0.0604,  0.1306],\n",
       "           [ 0.0372, -0.0075,  0.1282],\n",
       "           [-0.1164, -0.0910,  0.1299]],\n",
       " \n",
       "          [[-0.0697,  0.0789,  0.0685],\n",
       "           [ 0.0942,  0.0137, -0.0512],\n",
       "           [ 0.0582, -0.0888, -0.0885]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0106, -0.0661,  0.0651],\n",
       "           [ 0.0635, -0.0420,  0.0731],\n",
       "           [-0.0161,  0.0537, -0.0714]],\n",
       " \n",
       "          [[-0.0699,  0.0877,  0.1029],\n",
       "           [ 0.0931, -0.0226, -0.0203],\n",
       "           [-0.0245, -0.0950, -0.1111]],\n",
       " \n",
       "          [[ 0.0586,  0.0683, -0.0011],\n",
       "           [-0.0734, -0.0426,  0.0548],\n",
       "           [-0.0224, -0.0174,  0.0427]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0928,  0.0457,  0.0526],\n",
       "           [-0.0438,  0.0321,  0.0829],\n",
       "           [-0.0327, -0.0409,  0.0381]],\n",
       " \n",
       "          [[-0.0824,  0.0694, -0.0059],\n",
       "           [-0.0007,  0.0691, -0.0486],\n",
       "           [ 0.0559, -0.0356,  0.0583]],\n",
       " \n",
       "          [[-0.0043, -0.0053, -0.0320],\n",
       "           [ 0.0346,  0.0019,  0.0095],\n",
       "           [ 0.0182,  0.0363, -0.0487]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0257, -0.0934,  0.0504],\n",
       "           [ 0.0109,  0.0283, -0.0864],\n",
       "           [-0.0510, -0.0759,  0.0417]],\n",
       " \n",
       "          [[ 0.0273,  0.0517, -0.0146],\n",
       "           [-0.0320,  0.0679, -0.0463],\n",
       "           [-0.0416, -0.0265,  0.0033]],\n",
       " \n",
       "          [[ 0.0936,  0.0555, -0.0068],\n",
       "           [-0.0236, -0.0367,  0.0605],\n",
       "           [ 0.0121, -0.0668,  0.0621]]],\n",
       " \n",
       " \n",
       "         [[[-0.0009,  0.0765,  0.0925],\n",
       "           [ 0.0332, -0.0377,  0.0487],\n",
       "           [-0.0576, -0.0178,  0.0087]],\n",
       " \n",
       "          [[-0.0696,  0.0398, -0.0136],\n",
       "           [ 0.0742, -0.0315, -0.1019],\n",
       "           [-0.0387, -0.0783, -0.0019]],\n",
       " \n",
       "          [[ 0.0117, -0.0056,  0.0403],\n",
       "           [-0.0759,  0.0449,  0.0630],\n",
       "           [-0.0384, -0.0337,  0.0241]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0432,  0.0007,  0.0081],\n",
       "           [ 0.0550,  0.0508, -0.0680],\n",
       "           [ 0.0326, -0.0328,  0.0851]],\n",
       " \n",
       "          [[ 0.0379,  0.0369,  0.0575],\n",
       "           [-0.0478,  0.0363, -0.0174],\n",
       "           [-0.0775, -0.0724,  0.0863]],\n",
       " \n",
       "          [[-0.0174,  0.0208, -0.0099],\n",
       "           [-0.0457,  0.0741,  0.0277],\n",
       "           [ 0.0886, -0.0095, -0.0190]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0500, -0.0442, -0.0377],\n",
       "           [-0.0677, -0.0449,  0.0679],\n",
       "           [-0.0811,  0.0552, -0.0004]],\n",
       " \n",
       "          [[-0.0719, -0.0242, -0.1092],\n",
       "           [-0.0490,  0.0303, -0.0357],\n",
       "           [-0.0316, -0.0222,  0.0255]],\n",
       " \n",
       "          [[-0.0615, -0.0627, -0.0573],\n",
       "           [-0.0355, -0.0957,  0.0772],\n",
       "           [-0.0308,  0.0572,  0.0508]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0448, -0.0669, -0.0811],\n",
       "           [ 0.0624, -0.0895, -0.0964],\n",
       "           [ 0.0184, -0.0039, -0.0512]],\n",
       " \n",
       "          [[ 0.0805, -0.0912,  0.0075],\n",
       "           [ 0.0731,  0.0126, -0.0659],\n",
       "           [ 0.0890, -0.0179, -0.0573]],\n",
       " \n",
       "          [[-0.0879, -0.0450, -0.0598],\n",
       "           [-0.0981, -0.1002,  0.0014],\n",
       "           [ 0.0503, -0.0279,  0.0934]]]], requires_grad=True),\n",
       " 'conv2.bias': Parameter containing:\n",
       " tensor([ 0.1083, -0.0428,  0.0261, -0.0588,  0.0754, -0.0130,  0.0453, -0.0889,\n",
       "          0.0503, -0.0053, -0.0332,  0.0353,  0.0808, -0.0280,  0.0177,  0.0331,\n",
       "         -0.0855,  0.0473,  0.0054,  0.0296], requires_grad=True),\n",
       " 'conv3.weight': Parameter containing:\n",
       " tensor([[[[-8.8055e-03, -3.2647e-02, -6.3535e-03],\n",
       "           [ 1.4722e-02,  5.2948e-02, -1.4292e-03],\n",
       "           [-4.7756e-02, -3.0532e-02, -5.6744e-02]],\n",
       " \n",
       "          [[-4.2847e-02,  1.5182e-02,  4.3784e-02],\n",
       "           [-1.9029e-02, -8.3445e-03, -1.8978e-02],\n",
       "           [-2.2323e-02,  3.1377e-02,  6.4780e-02]],\n",
       " \n",
       "          [[-1.7924e-02,  3.3247e-02,  4.4445e-02],\n",
       "           [-4.0685e-02,  2.4873e-02, -5.1730e-02],\n",
       "           [-7.8755e-02, -7.1070e-02, -8.5751e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.1732e-02, -3.2799e-02,  3.0254e-02],\n",
       "           [ 6.5894e-02, -2.9880e-02,  6.7545e-02],\n",
       "           [-6.6948e-02,  4.8937e-03, -4.8708e-02]],\n",
       " \n",
       "          [[ 3.0385e-02,  3.0355e-02, -1.6948e-02],\n",
       "           [ 4.2873e-02,  1.5337e-02, -9.9710e-03],\n",
       "           [-5.7654e-02, -1.3582e-02, -4.9667e-02]],\n",
       " \n",
       "          [[-3.1663e-02,  2.0124e-02,  5.7318e-02],\n",
       "           [-1.3864e-02, -3.3642e-02, -2.9844e-02],\n",
       "           [ 6.4510e-02,  5.2740e-02, -3.3338e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.6497e-02,  6.6564e-02, -6.9449e-02],\n",
       "           [ 5.3312e-02,  3.8020e-02, -9.6482e-03],\n",
       "           [-5.3422e-03, -1.1373e-02, -5.2940e-02]],\n",
       " \n",
       "          [[ 1.8584e-02,  5.0218e-02, -3.2254e-02],\n",
       "           [ 3.3479e-02,  4.6747e-02, -2.8548e-02],\n",
       "           [-6.1459e-02, -3.6170e-03, -2.2359e-02]],\n",
       " \n",
       "          [[-5.5618e-03,  5.8690e-02,  8.3045e-03],\n",
       "           [ 6.3158e-02, -6.2759e-02,  4.6132e-02],\n",
       "           [ 1.0994e-03, -3.3621e-02,  9.0865e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.0449e-02, -2.7021e-03,  6.3129e-02],\n",
       "           [-2.4586e-02, -1.2693e-02,  6.2863e-02],\n",
       "           [ 4.8231e-02, -6.3055e-02, -6.5465e-03]],\n",
       " \n",
       "          [[ 4.4606e-02,  4.9805e-02, -6.6658e-02],\n",
       "           [ 5.4820e-02, -2.8699e-02,  4.8812e-02],\n",
       "           [ 6.0705e-02,  5.9154e-02,  2.6165e-03]],\n",
       " \n",
       "          [[ 3.1218e-03,  9.2726e-03,  6.2205e-02],\n",
       "           [-4.2248e-02, -8.2452e-02,  7.6886e-02],\n",
       "           [ 1.9159e-02, -2.7369e-02,  7.0984e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.5677e-02, -2.2860e-02,  4.7333e-02],\n",
       "           [-1.3890e-02,  4.1260e-02, -2.7140e-02],\n",
       "           [-5.3596e-02, -1.8021e-02,  1.3492e-02]],\n",
       " \n",
       "          [[-2.6630e-02, -8.4387e-02,  6.7862e-02],\n",
       "           [-4.0343e-02, -6.3310e-02, -3.1529e-04],\n",
       "           [ 7.2998e-02, -1.6365e-02, -4.1965e-03]],\n",
       " \n",
       "          [[ 5.2423e-02, -5.8835e-03,  1.3225e-03],\n",
       "           [ 3.1202e-03,  3.3784e-03, -1.7443e-02],\n",
       "           [ 1.2356e-02, -8.6317e-02, -7.1884e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.9171e-02,  1.2183e-02, -7.9978e-02],\n",
       "           [ 4.1688e-02, -4.2155e-02,  1.7354e-02],\n",
       "           [-1.9419e-02, -1.3951e-02, -6.7878e-02]],\n",
       " \n",
       "          [[-2.2297e-02, -2.3681e-02,  6.1025e-02],\n",
       "           [ 5.8449e-02, -4.7852e-02,  4.4196e-02],\n",
       "           [ 7.0379e-02, -6.4761e-03,  7.3960e-02]],\n",
       " \n",
       "          [[ 1.1196e-03,  5.9938e-02, -3.3086e-02],\n",
       "           [-4.7666e-02, -9.8181e-03, -4.4827e-02],\n",
       "           [ 2.2933e-02,  5.9900e-02,  2.4854e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-4.8034e-02, -6.8701e-02,  5.2768e-02],\n",
       "           [ 1.0669e-02, -5.6246e-02, -2.1442e-02],\n",
       "           [-5.9076e-02,  3.5808e-02,  3.6311e-02]],\n",
       " \n",
       "          [[-3.9384e-02,  3.6603e-02,  5.0779e-02],\n",
       "           [-1.0410e-02,  3.5993e-02, -7.9075e-02],\n",
       "           [-6.1678e-02, -1.8942e-02, -4.0944e-02]],\n",
       " \n",
       "          [[ 1.0224e-02,  6.0082e-02,  3.8881e-02],\n",
       "           [-3.2191e-02,  5.8064e-03, -2.7973e-02],\n",
       "           [ 1.7937e-02,  2.5950e-03, -2.6172e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.2052e-02,  4.1985e-02, -2.8351e-02],\n",
       "           [-3.3753e-02,  3.2157e-03, -3.2108e-02],\n",
       "           [ 2.9188e-02,  7.0517e-03, -7.3909e-02]],\n",
       " \n",
       "          [[-1.8394e-03, -2.8569e-02, -4.4890e-02],\n",
       "           [ 4.3232e-02,  1.2250e-03,  2.5707e-02],\n",
       "           [ 6.6978e-02,  2.9137e-02,  1.7690e-02]],\n",
       " \n",
       "          [[-4.3755e-04,  1.0672e-02,  5.3720e-02],\n",
       "           [-6.8214e-02, -8.6199e-05,  1.3424e-02],\n",
       "           [-2.5254e-02, -4.8505e-03, -2.8973e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.1152e-02, -1.8699e-02,  4.0752e-02],\n",
       "           [ 7.1135e-02, -3.0865e-02, -6.1440e-02],\n",
       "           [ 3.1915e-02, -2.9286e-02, -5.9613e-02]],\n",
       " \n",
       "          [[ 5.1956e-02,  7.1322e-03, -1.1027e-01],\n",
       "           [ 8.1021e-03, -2.7728e-02, -6.7811e-02],\n",
       "           [-6.6372e-02,  4.3818e-02,  1.6118e-02]],\n",
       " \n",
       "          [[ 5.9036e-02,  1.2068e-05, -8.9124e-02],\n",
       "           [ 1.9650e-02,  5.9805e-02, -8.9688e-02],\n",
       "           [ 3.3001e-02, -1.9783e-02, -7.3526e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.7037e-02, -1.6539e-02,  2.3174e-02],\n",
       "           [ 4.3222e-02, -4.1562e-03,  3.7286e-02],\n",
       "           [ 4.0664e-02, -7.0692e-02,  9.8964e-03]],\n",
       " \n",
       "          [[ 5.7333e-02,  9.0914e-03, -3.6169e-02],\n",
       "           [ 4.8326e-02,  5.6484e-02,  5.7279e-02],\n",
       "           [-6.1712e-02,  6.9801e-02, -5.1795e-02]],\n",
       " \n",
       "          [[-4.8533e-02, -5.4891e-02,  5.9734e-02],\n",
       "           [-6.0501e-02,  2.5698e-02,  3.3894e-02],\n",
       "           [ 2.5873e-02, -1.2804e-02, -7.0110e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.3396e-02,  7.5637e-02,  4.5770e-02],\n",
       "           [ 5.0141e-03, -6.3854e-02, -6.9353e-02],\n",
       "           [ 1.2927e-02,  4.2585e-02,  5.9371e-02]],\n",
       " \n",
       "          [[-4.2853e-02,  2.5007e-02, -4.7403e-02],\n",
       "           [ 4.2876e-02,  5.8318e-02, -7.6894e-03],\n",
       "           [ 3.6451e-02,  4.4107e-02, -9.4078e-03]],\n",
       " \n",
       "          [[-7.8848e-03, -6.2299e-02,  5.8708e-02],\n",
       "           [-1.3151e-03, -3.6477e-02,  6.4456e-02],\n",
       "           [ 1.7412e-02, -1.8758e-02,  5.9017e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.4066e-03,  8.7048e-03, -4.7939e-02],\n",
       "           [-1.7183e-02,  2.6146e-02,  5.0317e-02],\n",
       "           [-4.5670e-02,  3.8174e-02,  1.0441e-02]],\n",
       " \n",
       "          [[-1.4486e-02,  6.6544e-03, -6.8594e-02],\n",
       "           [ 4.7908e-02, -3.7938e-02,  5.2682e-02],\n",
       "           [-4.2940e-02,  3.1719e-02, -6.6889e-02]],\n",
       " \n",
       "          [[ 6.8206e-02,  6.1955e-02,  5.6252e-02],\n",
       "           [ 6.3986e-02,  2.0504e-02,  6.1701e-02],\n",
       "           [ 1.1241e-02,  5.7144e-02, -2.3793e-02]]]], requires_grad=True),\n",
       " 'conv3.bias': Parameter containing:\n",
       " tensor([ 0.0469, -0.0631,  0.0102,  0.0251, -0.0474, -0.0935, -0.0494, -0.0689,\n",
       "         -0.0340, -0.0256,  0.0511,  0.0473, -0.0256, -0.0041, -0.0047, -0.0341,\n",
       "         -0.0089, -0.0270, -0.0278,  0.0821,  0.0523, -0.0040, -0.0484, -0.0588,\n",
       "          0.0610,  0.0128, -0.0220, -0.0492, -0.0495,  0.0256, -0.0053,  0.0407],\n",
       "        requires_grad=True),\n",
       " 'bn3.weight': Parameter containing:\n",
       " tensor([0.9700, 0.9602, 0.9594, 0.9756, 0.9742, 0.9691, 0.9716, 0.9714, 0.9705,\n",
       "         0.9656, 0.9751, 0.9745, 0.9675, 0.9520, 0.9652, 0.9749, 0.9697, 0.9658,\n",
       "         0.9632, 0.9738, 0.9717, 0.9768, 0.9629, 0.9662, 0.9729, 0.9640, 0.9592,\n",
       "         0.9661, 0.9510, 0.9737, 0.9558, 0.9734], requires_grad=True),\n",
       " 'bn3.bias': Parameter containing:\n",
       " tensor([-0.0226, -0.0403, -0.0451, -0.0209, -0.0257, -0.0297, -0.0201, -0.0313,\n",
       "         -0.0250, -0.0274, -0.0169, -0.0248, -0.0214, -0.0614, -0.0462, -0.0210,\n",
       "         -0.0250, -0.0466, -0.0301, -0.0214, -0.0272, -0.0203, -0.0415, -0.0474,\n",
       "         -0.0253, -0.0352, -0.0510, -0.0307, -0.0298, -0.0235, -0.0464, -0.0335],\n",
       "        requires_grad=True),\n",
       " 'fc.weight': Parameter containing:\n",
       " tensor([[ 0.0010,  0.0019,  0.0006,  ...,  0.0016, -0.0008, -0.0013],\n",
       "         [ 0.0010, -0.0023,  0.0013,  ..., -0.0015,  0.0004,  0.0006],\n",
       "         [ 0.0015,  0.0008,  0.0010,  ..., -0.0018, -0.0020, -0.0010]],\n",
       "        requires_grad=True),\n",
       " 'fc.bias': Parameter containing:\n",
       " tensor([-0.0012,  0.0002,  0.0018], requires_grad=True)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.get_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
