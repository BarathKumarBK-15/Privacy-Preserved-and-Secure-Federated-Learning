{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.nn import Module,Sequential,Linear,Conv2d,BatchNorm2d,ReLU,MaxPool2d\n",
    "from torch.utils.data import DataLoader\n",
    "import pathlib\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(4,5,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=3):\n",
    "        #giving default number of classes as 3\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Input shape= (batch_size,3,150,150)\n",
    "        # batch_size images in a batch x 3 channels(r,g,b) in an image x (150*150) pixels in an image.\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Applies 12 different filters and therefore obtains 12 different activation maps for all images in the btatch so only depth is changed\n",
    "        #Shape= (batch_size,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Number of features is only fed as the batchnorm input\n",
    "        #Shape= (batch_size,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (batch_size,12,150,150)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (batch_size,12,75,75)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (batch_size,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (batch_size,20,75,75)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (batch_size,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (batch_size,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (batch_size,32,75,75)\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Feed forwad function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "        #Above output will be in matrix form, with shape (batch_size,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "        #C-1 inferrs values from other dimensions to ensure the final dimension is equla to the previous end multiplication result(batch_size,32,75,75)\n",
    "        #batch_size entries with each entry as a single arra flattened from previous matrices . Each array length = 32*75*75\n",
    "            \n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(150),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes to be made in below cell :\n",
    "\n",
    "Make a way to slice the dataset for each client\n",
    "Compile everything to one single class\n",
    "So, take number of data samples and batch size as an input to the model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = '/Users/tarunvisvar/Downloads/Dataset/Handwriting/Handwriting-subset/Train'\n",
    "test_path = '/Users/tarunvisvar/Downloads/Dataset/Handwriting/Handwriting-subset/Test'\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform = preprocess),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform = preprocess),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iter(test_loader))*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pathlib.Path(train_path)\n",
    "classes = [dir.name for dir in root.iterdir()]\n",
    "classes.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reversal', 'Normal', 'Corrected']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes = 3)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the size of training and testing images\n",
    "\n",
    "train_count=len(glob.glob(train_path+'/**/*.png'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1040)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count,test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model notebook.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# The images(in batches) are preprocessed while brought up by the trainloader itself\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# The images(in batches) are passed through various layers and predictions are made.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Those are the outputs and are compared with the labels\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# The output is a batch_size length vector containing predicted output for batch_size images\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func(outputs,labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward() \u001b[39m# backpropagation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep() \u001b[39m# Updates the weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#print(\"loss.data = \",loss.data)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# For each image, we must add the loss to training loss. But loss is given for a batch by the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# So, we take the loss for a batch and multiply it with the batch size to get the loss for each image in an approximate manner\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "     model.train()\n",
    "     #Model will be in training mode and takes place on training dataset\n",
    "     train_loss = 0.0\n",
    "     train_accuracy = 0.0\n",
    "     for images,labels in train_loader:\n",
    "          # The loop runs for 'number of batches' times \n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(images) \n",
    "          # The images(in batches) are preprocessed while brought up by the trainloader itself\n",
    "          # The images(in batches) are passed through various layers and predictions are made.\n",
    "          # Those are the outputs and are compared with the labels\n",
    "          # The output is a batch_size length vector containing predicted output for batch_size images\n",
    "\n",
    "          loss = loss_func(outputs,labels)\n",
    "          loss.backward() # backpropagation\n",
    "          optimizer.step() # Updates the weights\n",
    "          #print(\"loss.data = \",loss.data)\n",
    "          \n",
    "          # For each image, we must add the loss to training loss. But loss is given for a batch by the model\n",
    "          # So, we take the loss for a batch and multiply it with the batch size to get the loss for each image in an approximate manner\n",
    "\n",
    "          train_loss += loss.data*batch_size\n",
    "          #print(outputs.data) #outputs will be of size 10 x 3, for 10 images in a batch and 3 predictions for each image in a batch\n",
    "          _,predictions = torch.max(outputs.data,1)\n",
    "          #print(predictions) #predictions will contain the indices of the highest value outputed for each image. Therefore, predictions will contain 10(batch_size) values of the indices(hence also the classes)\n",
    "          train_accuracy+=int(torch.sum(predictions==labels.data))\n",
    "     train_accuracy /= train_count\n",
    "     train_loss /= train_count\n",
    "     print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy))\n",
    "     model.eval()\n",
    "     #Modle will eb in the mode on evaluating on test dataset\n",
    "     test_accuracy = 0.0\n",
    "     for images,labels in test_loader:\n",
    "          outputs = model(images)\n",
    "          _,predictions = torch.max(outputs.data,1)\n",
    "          #print(outputs.data)\n",
    "          test_accuracy += int(torch.sum(predictions==labels.data))\n",
    "     test_accuracy /= test_count\n",
    "     print(\"Test accuracy =  \",str(test_accuracy))\n",
    "     if test_accuracy>best_accuracy:\n",
    "        torch.save(model,'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9596153846153846\n"
     ]
    }
   ],
   "source": [
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load('best_checkpoint.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight None\n",
      "conv1.bias None\n",
      "bn1.weight None\n",
      "bn1.bias None\n",
      "conv2.weight None\n",
      "conv2.bias None\n",
      "conv3.weight None\n",
      "conv3.bias None\n",
      "bn3.weight None\n",
      "bn3.bias None\n",
      "fc.weight None\n",
      "fc.bias None\n"
     ]
    }
   ],
   "source": [
    "for name,param in loaded_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name,param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548399"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference:\n",
    "\n",
    "Number of parameters in a model = around 5 and half lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HWRModel:\n",
    "    def __init__(self,data_path,batch_size,local_data_count):\n",
    "        self.batch_size = batch_size\n",
    "        self.train_path = data_path + '/Train'\n",
    "        self.test_path = data_path + '/Test'\n",
    "        self.local_data_count = local_data_count # Amount of data that a user can choose \n",
    "    \n",
    "    def preprocess(self,resize=150):\n",
    "        transformer = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(resize),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "            ]\n",
    "        )\n",
    "        return transformer   \n",
    "\n",
    "    def get_model(self):\n",
    "        model = ConvNet(num_classes = 3)\n",
    "        optimizer = Adam(model.parameters(), lr=0.001)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        return (model,optimizer,loss_func)\n",
    "    \n",
    "    #Add load dataset function.\n",
    "\n",
    "    def load_dataset(self):\n",
    "        train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(self.train_path,transform = self.preprocess()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(self.test_path,transform = self.preprocess()),\n",
    "    batch_size=batch_size, shuffle=True) \n",
    "\n",
    "        return(train_loader,test_loader)\n",
    "        \n",
    "    def train(self,num_epochs=10):\n",
    "        model,optimizer,loss_func = self.get_model()\n",
    "        best_accuracy = 0.0\n",
    "        train_loader,test_loader = self.load_dataset()\n",
    "        train_count=len(glob.glob(self.train_path+'/**/*.png'))\n",
    "        test_count=len(glob.glob(self.test_path+'/**/*.png'))\n",
    "\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            #Model will be in training mode and takes place on training dataset\n",
    "            train_loss = 0.0\n",
    "            train_accuracy = 0.0\n",
    "            for images,labels in train_loader:\n",
    "                # The loop runs for 'number of batches' times \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images) \n",
    "                # The images(in batches) are preprocessed while brought up by the trainloader itself\n",
    "                # The images(in batches) are passed through various layers and predictions are made.\n",
    "                # Those are the outputs and are compared with the labels\n",
    "                # The output is a batch_size length vector containing predicted output for batch_size images\n",
    "\n",
    "                loss = loss_func(outputs,labels)\n",
    "                loss.backward() # backpropagation\n",
    "                optimizer.step() # Updates the weights\n",
    "                #print(\"loss.data = \",loss.data)\n",
    "                \n",
    "                # For each image, we must add the loss to training loss. But loss is given for a batch by the model\n",
    "                # So, we take the loss for a batch and multiply it with the batch size to get the loss for each image in an approximate manner\n",
    "\n",
    "                train_loss += loss.data*batch_size\n",
    "                #print(outputs.data) #outputs will be of size 10 x 3, for 10 images in a batch and 3 predictions for each image in a batch\n",
    "                _,predictions = torch.max(outputs.data,1)\n",
    "                #print(predictions) #predictions will contain the indices of the highest value outputed for each image. Therefore, predictions will contain 10(batch_size) values of the indices(hence also the classes)\n",
    "                train_accuracy+=int(torch.sum(predictions==labels.data))\n",
    "            train_accuracy /= train_count\n",
    "            train_loss /= train_count\n",
    "            print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy))\n",
    "            model.eval()\n",
    "            #Modle will eb in the mode on evaluating on test dataset\n",
    "            test_accuracy = 0.0\n",
    "            for images,labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                _,predictions = torch.max(outputs.data,1)\n",
    "                #print(outputs.data)\n",
    "                test_accuracy += int(torch.sum(predictions==labels.data))\n",
    "            test_accuracy /= test_count\n",
    "            print(\"Test accuracy =  \",str(test_accuracy))\n",
    "            if test_accuracy>best_accuracy:\n",
    "                torch.save(model,'best_checkpoint.model')\n",
    "                best_accuracy=test_accuracy\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        loaded_model = torch.load('best_checkpoint.model')\n",
    "        params = dict()\n",
    "        for name,parameters in loaded_model.named_parameters():\n",
    "            params[name] = parameters\n",
    "        return params\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/tarunvisvar/Downloads/Dataset/Handwriting/Handwriting-subset'\n",
    "batch_size = 100\n",
    "local_data_count = 1000\n",
    "mymodel = HWRModel(data_path,batch_size,local_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(10.7369) Train Accuracy: 0.5585\n",
      "Test accuracy =   0.4913461538461538\n",
      "Epoch: 1 Train Loss: tensor(0.9976) Train Accuracy: 0.799\n",
      "Test accuracy =   0.46923076923076923\n",
      "Epoch: 2 Train Loss: tensor(0.5559) Train Accuracy: 0.83675\n",
      "Test accuracy =   0.8769230769230769\n",
      "Epoch: 3 Train Loss: tensor(0.3880) Train Accuracy: 0.8765\n",
      "Test accuracy =   0.9807692307692307\n",
      "Epoch: 4 Train Loss: tensor(0.4969) Train Accuracy: 0.8585\n",
      "Test accuracy =   0.8278846153846153\n",
      "Epoch: 5 Train Loss: tensor(0.5767) Train Accuracy: 0.86\n",
      "Test accuracy =   0.5403846153846154\n",
      "Epoch: 6 Train Loss: tensor(0.5643) Train Accuracy: 0.86275\n",
      "Test accuracy =   0.8903846153846153\n",
      "Epoch: 7 Train Loss: tensor(0.3784) Train Accuracy: 0.887\n",
      "Test accuracy =   0.9307692307692308\n",
      "Epoch: 8 Train Loss: tensor(0.4004) Train Accuracy: 0.89475\n",
      "Test accuracy =   0.9288461538461539\n",
      "Epoch: 9 Train Loss: tensor(0.3224) Train Accuracy: 0.9025\n",
      "Test accuracy =   0.9442307692307692\n"
     ]
    }
   ],
   "source": [
    "mymodel.train(num_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1.weight': Parameter containing:\n",
       " tensor([[[[ 0.1690,  0.1080,  0.0092],\n",
       "           [ 0.1585,  0.0621, -0.0139],\n",
       "           [ 0.0812,  0.1706,  0.1587]],\n",
       " \n",
       "          [[ 0.1087,  0.0890, -0.1338],\n",
       "           [ 0.0097,  0.1451,  0.1072],\n",
       "           [-0.1238, -0.0284, -0.1168]],\n",
       " \n",
       "          [[ 0.1852,  0.0462, -0.0201],\n",
       "           [-0.0992, -0.0722, -0.0999],\n",
       "           [ 0.0374,  0.0253,  0.1712]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1264,  0.0022, -0.0193],\n",
       "           [ 0.0385,  0.1762,  0.1856],\n",
       "           [-0.0569, -0.1628, -0.1351]],\n",
       " \n",
       "          [[ 0.1566,  0.1380, -0.0630],\n",
       "           [-0.0288, -0.1585,  0.1070],\n",
       "           [ 0.1057,  0.1422, -0.0259]],\n",
       " \n",
       "          [[-0.0477,  0.1349,  0.1011],\n",
       "           [-0.1836,  0.0726, -0.1369],\n",
       "           [ 0.0583, -0.1209, -0.1937]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0687,  0.0492, -0.1707],\n",
       "           [-0.1670, -0.1787, -0.1919],\n",
       "           [-0.0685, -0.0459,  0.0223]],\n",
       " \n",
       "          [[ 0.1041,  0.0377, -0.0591],\n",
       "           [-0.0703,  0.0399,  0.0466],\n",
       "           [-0.0945, -0.1167, -0.0385]],\n",
       " \n",
       "          [[-0.0349, -0.1892,  0.0176],\n",
       "           [ 0.0072, -0.1426, -0.1676],\n",
       "           [ 0.0454,  0.0372,  0.1760]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1448,  0.0866, -0.0256],\n",
       "           [-0.0886,  0.1380,  0.0853],\n",
       "           [-0.1387, -0.0735, -0.1199]],\n",
       " \n",
       "          [[-0.1466,  0.0656,  0.1447],\n",
       "           [ 0.1850, -0.0205, -0.0388],\n",
       "           [-0.0435,  0.0003, -0.0180]],\n",
       " \n",
       "          [[-0.0978,  0.1103, -0.0746],\n",
       "           [-0.1176, -0.1113, -0.1347],\n",
       "           [-0.1408, -0.0578,  0.1116]]],\n",
       " \n",
       " \n",
       "         [[[-0.0618, -0.1606,  0.0246],\n",
       "           [-0.1000, -0.0955,  0.1502],\n",
       "           [-0.1312, -0.0932,  0.1394]],\n",
       " \n",
       "          [[-0.0866, -0.1658, -0.0409],\n",
       "           [-0.0357,  0.0442,  0.0710],\n",
       "           [-0.1318,  0.0071, -0.1717]],\n",
       " \n",
       "          [[-0.1602,  0.1739,  0.0025],\n",
       "           [-0.0788, -0.0450, -0.1039],\n",
       "           [ 0.0916,  0.0628,  0.1133]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0789, -0.0857,  0.0191],\n",
       "           [-0.1576, -0.1383, -0.1096],\n",
       "           [-0.1609,  0.0422,  0.0774]],\n",
       " \n",
       "          [[ 0.0096, -0.1655, -0.0101],\n",
       "           [ 0.1739, -0.0545,  0.0638],\n",
       "           [-0.1983, -0.1672, -0.0580]],\n",
       " \n",
       "          [[ 0.0899, -0.0958,  0.1822],\n",
       "           [ 0.1168, -0.0017, -0.0397],\n",
       "           [-0.1194, -0.0658, -0.1066]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0033,  0.1179,  0.0833],\n",
       "           [ 0.1735,  0.1863,  0.0224],\n",
       "           [ 0.0286,  0.0938,  0.1828]],\n",
       " \n",
       "          [[-0.0059, -0.0512, -0.1890],\n",
       "           [ 0.1072, -0.1228, -0.0540],\n",
       "           [ 0.0883, -0.0885, -0.1920]],\n",
       " \n",
       "          [[-0.1691,  0.0666,  0.1289],\n",
       "           [ 0.0828,  0.0082,  0.1273],\n",
       "           [ 0.1496,  0.1070,  0.0488]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1672, -0.0445, -0.1125],\n",
       "           [-0.1416,  0.1250, -0.1106],\n",
       "           [ 0.1508,  0.1456,  0.0076]],\n",
       " \n",
       "          [[-0.0728,  0.1474, -0.0168],\n",
       "           [-0.0552,  0.1643, -0.0755],\n",
       "           [-0.0349, -0.0874, -0.0147]],\n",
       " \n",
       "          [[ 0.0286,  0.1977, -0.0114],\n",
       "           [ 0.0013, -0.1517, -0.1108],\n",
       "           [-0.0265, -0.1364, -0.1292]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0712, -0.0605, -0.1343],\n",
       "           [ 0.1835, -0.1629,  0.1361],\n",
       "           [-0.1233, -0.1660, -0.0927]],\n",
       " \n",
       "          [[ 0.1106, -0.1475,  0.1878],\n",
       "           [-0.0965,  0.2025,  0.0113],\n",
       "           [ 0.1339, -0.0127,  0.0362]],\n",
       " \n",
       "          [[-0.0690, -0.0609, -0.1801],\n",
       "           [-0.0317,  0.1230, -0.1573],\n",
       "           [ 0.0197, -0.0161,  0.1880]]],\n",
       " \n",
       " \n",
       "         [[[-0.1298,  0.0751, -0.0710],\n",
       "           [ 0.1697,  0.1294,  0.1033],\n",
       "           [-0.0905, -0.0093, -0.1224]],\n",
       " \n",
       "          [[-0.1476, -0.1526,  0.0173],\n",
       "           [ 0.1498,  0.0074,  0.0794],\n",
       "           [-0.1042, -0.0555,  0.1454]],\n",
       " \n",
       "          [[ 0.0778, -0.1777, -0.1358],\n",
       "           [-0.0378,  0.0083, -0.1069],\n",
       "           [ 0.0117,  0.1306,  0.0645]]],\n",
       " \n",
       " \n",
       "         [[[-0.0646,  0.0441, -0.0263],\n",
       "           [-0.0790,  0.0080,  0.0158],\n",
       "           [-0.1473,  0.0303, -0.0475]],\n",
       " \n",
       "          [[-0.0377,  0.1604, -0.0855],\n",
       "           [-0.1019,  0.1791, -0.0212],\n",
       "           [-0.1388,  0.0560, -0.1550]],\n",
       " \n",
       "          [[ 0.1535,  0.1098,  0.1953],\n",
       "           [-0.1173,  0.0246, -0.0660],\n",
       "           [ 0.0857, -0.0864,  0.0957]]],\n",
       " \n",
       " \n",
       "         [[[-0.0680, -0.0667,  0.0207],\n",
       "           [ 0.0840, -0.0242,  0.1084],\n",
       "           [-0.0695, -0.1707,  0.1379]],\n",
       " \n",
       "          [[-0.0105, -0.0050, -0.0600],\n",
       "           [ 0.0604, -0.1650, -0.0530],\n",
       "           [ 0.1403, -0.1209,  0.0102]],\n",
       " \n",
       "          [[ 0.1355,  0.0841, -0.0350],\n",
       "           [ 0.1653, -0.0237, -0.1760],\n",
       "           [-0.1318,  0.1175,  0.0625]]]], requires_grad=True),\n",
       " 'conv1.bias': Parameter containing:\n",
       " tensor([ 0.0333, -0.1028, -0.1783, -0.0003, -0.1882, -0.0986, -0.1893,  0.1145,\n",
       "         -0.0866, -0.0610, -0.1667, -0.1822], requires_grad=True),\n",
       " 'bn1.weight': Parameter containing:\n",
       " tensor([1.0029, 0.9965, 1.0005, 0.9986, 0.9884, 0.9940, 0.9841, 0.9956, 0.9979,\n",
       "         1.0138, 1.0158, 1.0131], requires_grad=True),\n",
       " 'bn1.bias': Parameter containing:\n",
       " tensor([-5.1283e-04, -6.4323e-03, -2.4390e-05, -1.7651e-03, -8.9342e-03,\n",
       "         -5.7685e-03, -2.0065e-02, -3.2193e-03, -3.4421e-03,  1.0681e-02,\n",
       "         -1.1722e-05, -1.6649e-05], requires_grad=True),\n",
       " 'conv2.weight': Parameter containing:\n",
       " tensor([[[[-2.9581e-02, -1.0355e-01, -6.7477e-02],\n",
       "           [-9.0063e-02, -6.9877e-02, -4.7858e-02],\n",
       "           [-4.5562e-02,  8.0020e-02, -5.1389e-02]],\n",
       " \n",
       "          [[-7.8559e-02,  7.9549e-03,  8.3875e-02],\n",
       "           [ 3.8661e-02, -1.2260e-02, -1.7977e-02],\n",
       "           [-5.8487e-02,  5.6166e-02, -1.4535e-02]],\n",
       " \n",
       "          [[ 5.9892e-02,  9.4151e-02,  5.5774e-02],\n",
       "           [ 7.4173e-02,  8.3099e-02,  3.9893e-02],\n",
       "           [-6.0976e-02,  9.6924e-02, -8.4641e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.2816e-02,  5.4100e-02,  5.2588e-02],\n",
       "           [-5.0183e-02,  9.6162e-02,  9.0636e-02],\n",
       "           [ 8.1194e-02,  7.2597e-02,  1.6956e-02]],\n",
       " \n",
       "          [[ 4.3188e-02, -9.4606e-02, -1.2704e-02],\n",
       "           [ 5.6579e-02,  5.6204e-02, -1.7665e-03],\n",
       "           [-4.5739e-02,  4.6937e-02, -1.9361e-02]],\n",
       " \n",
       "          [[ 4.8900e-02,  1.1382e-01,  6.6261e-02],\n",
       "           [ 4.2629e-02,  2.0498e-02, -5.2871e-02],\n",
       "           [ 3.3609e-02,  3.7995e-02,  3.2146e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.0679e-04, -8.7520e-02,  5.6318e-02],\n",
       "           [-3.9006e-02, -1.6428e-02, -4.4588e-02],\n",
       "           [-6.0934e-02, -4.2076e-02,  5.1802e-03]],\n",
       " \n",
       "          [[ 1.8089e-03,  7.5996e-02, -3.8188e-02],\n",
       "           [ 2.6742e-02, -7.3892e-02, -6.7374e-02],\n",
       "           [ 3.5664e-02, -4.9807e-04,  7.9432e-02]],\n",
       " \n",
       "          [[ 5.9482e-02, -6.3383e-03, -5.9167e-02],\n",
       "           [-1.6951e-02, -4.2799e-02, -1.1661e-02],\n",
       "           [ 3.5628e-02, -9.0178e-02, -8.1441e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.5148e-02,  7.4991e-02,  4.2099e-02],\n",
       "           [ 8.0819e-03,  5.6454e-02, -6.7066e-02],\n",
       "           [-8.7436e-03,  3.6932e-02, -6.7762e-02]],\n",
       " \n",
       "          [[ 1.7395e-03, -3.5907e-02,  1.0259e-01],\n",
       "           [-2.3145e-02, -7.3621e-02,  8.3420e-03],\n",
       "           [ 2.6674e-02, -6.5446e-02,  4.6056e-02]],\n",
       " \n",
       "          [[ 8.5459e-02,  7.6174e-02,  1.4739e-02],\n",
       "           [ 7.9867e-05,  6.7990e-02,  7.3556e-02],\n",
       "           [ 1.7436e-02,  6.7159e-02,  5.5183e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.7864e-02,  6.6015e-02,  4.3553e-02],\n",
       "           [ 1.6745e-02, -7.0479e-02, -4.5024e-02],\n",
       "           [-8.3287e-02,  9.6133e-02,  3.1174e-02]],\n",
       " \n",
       "          [[ 5.3384e-02, -6.4067e-02,  1.0888e-02],\n",
       "           [-6.5651e-02, -6.4035e-02,  5.7216e-02],\n",
       "           [-4.8081e-02, -5.1300e-02, -6.7089e-02]],\n",
       " \n",
       "          [[-3.0936e-02, -5.6848e-02, -3.7239e-02],\n",
       "           [ 6.3156e-03, -9.5923e-02,  5.1769e-02],\n",
       "           [-7.3672e-02,  6.2075e-02,  6.2906e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.9503e-02,  3.7658e-02, -5.7580e-02],\n",
       "           [ 8.9143e-02,  9.9097e-02, -5.7956e-02],\n",
       "           [-4.4953e-02,  8.4891e-02,  2.1986e-02]],\n",
       " \n",
       "          [[ 4.5539e-02,  3.1047e-02,  6.3450e-02],\n",
       "           [-8.1068e-03,  5.4023e-02,  7.0596e-02],\n",
       "           [-1.0169e-01, -1.9726e-02, -5.8595e-02]],\n",
       " \n",
       "          [[-5.4613e-02, -3.0741e-02, -2.1339e-02],\n",
       "           [ 5.0051e-02, -2.4184e-02,  1.6761e-02],\n",
       "           [ 7.6598e-02,  7.4636e-02,  6.9621e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-9.7888e-03, -9.3482e-02, -6.3741e-02],\n",
       "           [ 8.1521e-02, -1.7379e-02, -8.3273e-04],\n",
       "           [-6.6255e-02, -2.9948e-02,  5.4516e-02]],\n",
       " \n",
       "          [[ 2.9991e-02,  7.9877e-02,  4.5471e-02],\n",
       "           [-8.3419e-03,  8.1324e-02, -7.9723e-02],\n",
       "           [ 5.1780e-02,  6.1395e-02,  1.5954e-02]],\n",
       " \n",
       "          [[-3.6903e-02, -6.3574e-02, -9.0818e-02],\n",
       "           [ 7.0082e-02,  5.3737e-02, -6.3651e-02],\n",
       "           [ 8.7065e-02,  7.0826e-02, -8.6424e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-9.2516e-02,  8.3822e-02,  8.6499e-02],\n",
       "           [ 6.2223e-02,  9.0838e-02,  8.9789e-02],\n",
       "           [-4.7262e-02, -3.9658e-02, -8.1040e-02]],\n",
       " \n",
       "          [[ 3.9961e-02,  6.0603e-02,  1.1092e-01],\n",
       "           [ 2.3739e-02, -6.6023e-02, -9.2920e-02],\n",
       "           [-2.5203e-02,  5.0759e-02,  8.0042e-02]],\n",
       " \n",
       "          [[-4.2090e-02, -4.1978e-02, -7.9045e-02],\n",
       "           [ 5.6618e-02, -5.2782e-02,  5.7384e-02],\n",
       "           [ 9.0638e-02, -1.9632e-02, -9.0451e-02]]],\n",
       " \n",
       " \n",
       "         [[[-6.9865e-02, -7.3289e-02, -3.8146e-02],\n",
       "           [ 5.9883e-02, -3.5252e-02,  3.6826e-02],\n",
       "           [-6.8263e-02,  4.9635e-02, -6.7034e-02]],\n",
       " \n",
       "          [[-8.8297e-02,  5.8752e-02, -2.1318e-02],\n",
       "           [-6.0840e-02,  6.2033e-02,  6.8407e-02],\n",
       "           [ 4.1103e-02, -2.6160e-02, -1.6964e-02]],\n",
       " \n",
       "          [[ 8.6763e-03,  6.1177e-02,  4.4045e-02],\n",
       "           [ 5.9683e-02, -2.2915e-03, -8.3403e-02],\n",
       "           [ 7.9569e-02, -1.1214e-01,  4.6371e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.1055e-02, -8.2262e-02,  5.5846e-02],\n",
       "           [-6.3690e-02, -3.6194e-03,  7.5054e-02],\n",
       "           [-6.1899e-02,  8.1643e-02,  7.5603e-02]],\n",
       " \n",
       "          [[-3.9096e-02, -1.3164e-02,  1.1664e-02],\n",
       "           [ 1.1977e-02, -8.5414e-02, -2.8497e-02],\n",
       "           [-6.1798e-02, -7.8161e-02,  4.5314e-02]],\n",
       " \n",
       "          [[-7.5216e-02, -3.8601e-02, -6.6238e-02],\n",
       "           [-6.7024e-02, -8.8677e-02, -4.7053e-02],\n",
       "           [ 5.5542e-02, -7.2372e-02, -9.0389e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.8241e-02,  1.0047e-01, -4.9521e-02],\n",
       "           [ 4.4863e-02,  2.1203e-02, -5.1229e-02],\n",
       "           [-4.4362e-02,  2.4808e-02,  4.0569e-02]],\n",
       " \n",
       "          [[-7.2964e-02, -3.5050e-02,  8.3943e-02],\n",
       "           [ 8.4086e-02, -5.4927e-02,  3.6825e-02],\n",
       "           [-8.7953e-02,  6.7331e-02, -9.4138e-02]],\n",
       " \n",
       "          [[-8.7102e-02, -1.6023e-02,  1.3470e-03],\n",
       "           [-1.3045e-02,  2.4705e-02, -3.4501e-02],\n",
       "           [-5.8251e-03,  3.3160e-02,  7.3277e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-9.9482e-02, -9.7958e-02,  2.3135e-02],\n",
       "           [-2.5952e-02, -3.5190e-03, -1.2961e-02],\n",
       "           [-5.2296e-02, -5.2147e-02, -4.5301e-02]],\n",
       " \n",
       "          [[-8.2191e-02, -7.1321e-02, -1.3863e-02],\n",
       "           [-4.2807e-02,  5.1332e-02, -1.0511e-01],\n",
       "           [-4.4268e-02, -5.9226e-02,  8.8559e-02]],\n",
       " \n",
       "          [[-1.0617e-02, -3.4081e-02,  5.9324e-02],\n",
       "           [ 4.0815e-03,  9.0773e-02,  5.4408e-02],\n",
       "           [-5.8625e-02, -5.0211e-03,  3.3607e-02]]]], requires_grad=True),\n",
       " 'conv2.bias': Parameter containing:\n",
       " tensor([ 0.0864, -0.0792,  0.0178, -0.0434, -0.0408, -0.0439, -0.0169, -0.0875,\n",
       "         -0.0663,  0.0443,  0.0831, -0.0013,  0.0162, -0.0743, -0.0258, -0.0157,\n",
       "          0.0332,  0.0485, -0.0103, -0.0907], requires_grad=True),\n",
       " 'conv3.weight': Parameter containing:\n",
       " tensor([[[[-0.0651,  0.0392, -0.0367],\n",
       "           [ 0.0599, -0.0083,  0.0123],\n",
       "           [ 0.0361, -0.0540,  0.0649]],\n",
       " \n",
       "          [[ 0.0050, -0.0445, -0.0717],\n",
       "           [ 0.0336, -0.0684, -0.0065],\n",
       "           [ 0.0428,  0.0362, -0.0568]],\n",
       " \n",
       "          [[-0.0111,  0.0156,  0.0634],\n",
       "           [-0.0274, -0.0059, -0.0496],\n",
       "           [ 0.0626, -0.0461, -0.0454]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0760,  0.0555,  0.0051],\n",
       "           [-0.0166,  0.0662, -0.0501],\n",
       "           [ 0.0313,  0.0491, -0.0617]],\n",
       " \n",
       "          [[ 0.0188,  0.0521,  0.0551],\n",
       "           [-0.0727, -0.0465,  0.0040],\n",
       "           [-0.0022, -0.0403,  0.0799]],\n",
       " \n",
       "          [[ 0.0364,  0.0462,  0.0509],\n",
       "           [ 0.0383, -0.0668, -0.0321],\n",
       "           [-0.0244, -0.0521, -0.0353]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0206, -0.0397, -0.0657],\n",
       "           [ 0.0706, -0.0726, -0.0189],\n",
       "           [-0.0732, -0.0445, -0.0615]],\n",
       " \n",
       "          [[-0.0652, -0.0157,  0.0329],\n",
       "           [ 0.0010,  0.0258, -0.0118],\n",
       "           [ 0.0201,  0.0245, -0.0572]],\n",
       " \n",
       "          [[ 0.0428, -0.0065,  0.0529],\n",
       "           [-0.0288,  0.0306, -0.0650],\n",
       "           [-0.0427,  0.0409,  0.0688]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0427,  0.0725,  0.0869],\n",
       "           [-0.0625, -0.0647,  0.0245],\n",
       "           [-0.0560, -0.0486,  0.0500]],\n",
       " \n",
       "          [[-0.0028, -0.0606, -0.0261],\n",
       "           [-0.0617, -0.0711,  0.0462],\n",
       "           [-0.0905, -0.0303, -0.0847]],\n",
       " \n",
       "          [[ 0.0647,  0.0191, -0.0647],\n",
       "           [ 0.0179,  0.0112, -0.0010],\n",
       "           [-0.0214,  0.0483, -0.0658]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0222, -0.0374, -0.0322],\n",
       "           [ 0.0204, -0.0354,  0.0307],\n",
       "           [ 0.0246,  0.0121,  0.0267]],\n",
       " \n",
       "          [[ 0.0345, -0.0346, -0.0311],\n",
       "           [ 0.0024,  0.0436,  0.0199],\n",
       "           [ 0.0112, -0.0752, -0.0357]],\n",
       " \n",
       "          [[ 0.0133,  0.0577,  0.0561],\n",
       "           [-0.0731, -0.0618,  0.0229],\n",
       "           [ 0.0202, -0.0878, -0.0984]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0354, -0.0323,  0.0481],\n",
       "           [ 0.0212, -0.0008,  0.0078],\n",
       "           [-0.0356, -0.0720, -0.0293]],\n",
       " \n",
       "          [[-0.0247,  0.0339, -0.0319],\n",
       "           [-0.0544,  0.0041,  0.0209],\n",
       "           [-0.0532, -0.0101, -0.0308]],\n",
       " \n",
       "          [[-0.0054, -0.0446, -0.0621],\n",
       "           [-0.0141,  0.0792,  0.0269],\n",
       "           [-0.0521, -0.0153, -0.0132]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0239, -0.0388, -0.0669],\n",
       "           [ 0.0335, -0.0750, -0.0550],\n",
       "           [ 0.0090, -0.0620,  0.0573]],\n",
       " \n",
       "          [[-0.0450, -0.0631, -0.0128],\n",
       "           [ 0.0657,  0.0426,  0.0268],\n",
       "           [-0.0126, -0.0303, -0.0099]],\n",
       " \n",
       "          [[-0.0075, -0.0387, -0.0663],\n",
       "           [ 0.0463,  0.0590, -0.0101],\n",
       "           [-0.0494,  0.0021, -0.0086]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0057,  0.0537,  0.0598],\n",
       "           [-0.0588, -0.0321, -0.0258],\n",
       "           [-0.0072,  0.0066, -0.0690]],\n",
       " \n",
       "          [[ 0.0345,  0.0252, -0.0253],\n",
       "           [-0.0664,  0.0719,  0.0618],\n",
       "           [ 0.0746,  0.0589,  0.0940]],\n",
       " \n",
       "          [[ 0.0131, -0.0595,  0.0324],\n",
       "           [-0.0324, -0.0487, -0.0348],\n",
       "           [-0.0420, -0.0743,  0.0727]]],\n",
       " \n",
       " \n",
       "         [[[-0.0046,  0.0116,  0.0527],\n",
       "           [ 0.0540,  0.0358,  0.0148],\n",
       "           [ 0.0582, -0.0145, -0.0652]],\n",
       " \n",
       "          [[ 0.0074, -0.0719, -0.0357],\n",
       "           [ 0.0286,  0.0540,  0.0343],\n",
       "           [-0.0042, -0.0195, -0.0524]],\n",
       " \n",
       "          [[-0.0374, -0.0132,  0.0689],\n",
       "           [ 0.0297, -0.0636, -0.0647],\n",
       "           [ 0.0555, -0.0089, -0.0203]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0192,  0.0319, -0.0650],\n",
       "           [ 0.0354, -0.0416,  0.0175],\n",
       "           [-0.0725, -0.0727, -0.0292]],\n",
       " \n",
       "          [[ 0.0794,  0.0265, -0.0094],\n",
       "           [ 0.0287, -0.0540,  0.0388],\n",
       "           [-0.0346, -0.0790, -0.0049]],\n",
       " \n",
       "          [[ 0.0422, -0.0246,  0.0463],\n",
       "           [-0.0564,  0.0196,  0.0676],\n",
       "           [ 0.0667, -0.0113,  0.0320]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0503, -0.0595,  0.0774],\n",
       "           [-0.0357, -0.0134, -0.0533],\n",
       "           [ 0.0446,  0.0548,  0.0275]],\n",
       " \n",
       "          [[ 0.0081, -0.0744, -0.0592],\n",
       "           [-0.0294, -0.0548,  0.0905],\n",
       "           [ 0.0076,  0.0141,  0.0750]],\n",
       " \n",
       "          [[ 0.0599,  0.0289,  0.0086],\n",
       "           [-0.0611,  0.0589,  0.0547],\n",
       "           [-0.0232, -0.0788,  0.0245]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0049, -0.0593,  0.0671],\n",
       "           [ 0.0542, -0.0232, -0.0345],\n",
       "           [ 0.0114, -0.0022, -0.0154]],\n",
       " \n",
       "          [[-0.0081, -0.0733,  0.0584],\n",
       "           [-0.0111,  0.0342,  0.0245],\n",
       "           [-0.0686, -0.0469,  0.0312]],\n",
       " \n",
       "          [[-0.0494,  0.0365, -0.0400],\n",
       "           [-0.0487,  0.0114,  0.0226],\n",
       "           [ 0.0755, -0.0387,  0.0576]]]], requires_grad=True),\n",
       " 'conv3.bias': Parameter containing:\n",
       " tensor([-0.0671,  0.0733,  0.0096, -0.0727,  0.0311,  0.0639, -0.0047, -0.0448,\n",
       "          0.0096,  0.0649, -0.0226,  0.0516,  0.0128, -0.0546,  0.0039, -0.0034,\n",
       "         -0.0178, -0.0527,  0.0472,  0.0398,  0.0530, -0.0598,  0.0752,  0.0351,\n",
       "          0.0288, -0.0003, -0.0088,  0.0388,  0.0123, -0.0500,  0.0282,  0.0155],\n",
       "        requires_grad=True),\n",
       " 'bn3.weight': Parameter containing:\n",
       " tensor([0.9770, 0.9693, 0.9696, 0.9717, 0.9743, 0.9766, 0.9732, 0.9713, 0.9705,\n",
       "         0.9733, 0.9649, 0.9740, 0.9784, 0.9737, 0.9769, 0.9778, 0.9689, 0.9798,\n",
       "         0.9751, 0.9752, 0.9846, 0.9753, 0.9787, 0.9759, 0.9762, 0.9757, 0.9781,\n",
       "         0.9705, 0.9744, 0.9787, 0.9750, 0.9740], requires_grad=True),\n",
       " 'bn3.bias': Parameter containing:\n",
       " tensor([-0.0168, -0.0259, -0.0312, -0.0172, -0.0182, -0.0207, -0.0143, -0.0212,\n",
       "         -0.0261, -0.0227, -0.0241, -0.0255, -0.0213, -0.0228, -0.0158, -0.0226,\n",
       "         -0.0342, -0.0192, -0.0211, -0.0209, -0.0107, -0.0252, -0.0202, -0.0214,\n",
       "         -0.0188, -0.0161, -0.0196, -0.0267, -0.0211, -0.0216, -0.0185, -0.0196],\n",
       "        requires_grad=True),\n",
       " 'fc.weight': Parameter containing:\n",
       " tensor([[-1.4488e-03,  2.9748e-05, -2.0764e-03,  ...,  1.0714e-03,\n",
       "           6.6469e-04,  7.2431e-04],\n",
       "         [-2.0523e-03,  2.0671e-03, -7.7102e-04,  ...,  1.8937e-03,\n",
       "          -1.5695e-03, -4.6780e-03],\n",
       "         [ 9.0031e-04,  6.2886e-04, -1.3998e-04,  ...,  1.1967e-03,\n",
       "           1.4720e-03,  4.3587e-03]], requires_grad=True),\n",
       " 'fc.bias': Parameter containing:\n",
       " tensor([-0.0018, -0.0010,  0.0020], requires_grad=True)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tenseal as ts\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def context():\n",
    "        context = ts.context(ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[60, 40, 40, 60])\n",
    "        context.global_scale = pow(2, 40)\n",
    "        context.generate_galois_keys()\n",
    "        return context\n",
    "context = context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0]],\n",
       " [[1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0]]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.ones(2,7,5).tolist()\n",
    "tensor2 = (torch.ones(2,7,5)*2).tolist()\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can only encrypt a vector",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model notebook.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m e1 \u001b[39m=\u001b[39m ts\u001b[39m.\u001b[39;49mckks_vector(context,tensor1)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m e2 \u001b[39m=\u001b[39m ts\u001b[39m.\u001b[39mckks_vector(context,tensor2)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tenseal/__init__.py:102\u001b[0m, in \u001b[0;36mckks_vector\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mckks_vector\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m CKKSVector:\n\u001b[1;32m    101\u001b[0m     \u001b[39m\"\"\"Constructor function for tenseal.CKKSVector\"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[39mreturn\u001b[39;00m CKKSVector(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tenseal/tensors/ckksvector.py:38\u001b[0m, in \u001b[0;36mCKKSVector.__init__\u001b[0;34m(self, context, vector, scale, data)\u001b[0m\n\u001b[1;32m     36\u001b[0m     vector \u001b[39m=\u001b[39m ts\u001b[39m.\u001b[39mplain_tensor(vector, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(vector\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcan only encrypt a vector\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m vector \u001b[39m=\u001b[39m vector\u001b[39m.\u001b[39mraw\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m scale \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: can only encrypt a vector"
     ]
    }
   ],
   "source": [
    "e1 = ts.ckks_vector(context,tensor1)\n",
    "e2 = ts.ckks_vector(context,tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (e1+e2)/torch.tensor(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.7500001010717946,\n",
       "   0.7500001003320794,\n",
       "   0.7500001009309527,\n",
       "   0.7500001009210692,\n",
       "   0.7500001006628408],\n",
       "  [0.7500001004724166,\n",
       "   0.7500001007525392,\n",
       "   0.7500001006204756,\n",
       "   0.7500001006311938,\n",
       "   0.7500001001151912],\n",
       "  [0.7500001002614758,\n",
       "   0.7500001003634575,\n",
       "   0.7500001006781736,\n",
       "   0.7500001004644928,\n",
       "   0.7500001006616509],\n",
       "  [0.7500001004289406,\n",
       "   0.7500000999360765,\n",
       "   0.7500001004811281,\n",
       "   0.7500001006519728,\n",
       "   0.7500001001827724],\n",
       "  [0.7500001006188527,\n",
       "   0.7500001002779706,\n",
       "   0.7500001006492009,\n",
       "   0.7500001001849537,\n",
       "   0.7500001005577396],\n",
       "  [0.7500001008058593,\n",
       "   0.7500001007423871,\n",
       "   0.750000100504571,\n",
       "   0.750000100304499,\n",
       "   0.7500001003951088],\n",
       "  [0.750000100500891,\n",
       "   0.750000100750282,\n",
       "   0.750000100533334,\n",
       "   0.7500001006834965,\n",
       "   0.7500001005819599]],\n",
       " [[0.7500001006871776,\n",
       "   0.7500001002942924,\n",
       "   0.7500001008281463,\n",
       "   0.7500001009770606,\n",
       "   0.7500001008488538],\n",
       "  [0.750000101080207,\n",
       "   0.7500001011238765,\n",
       "   0.7500001005462207,\n",
       "   0.7500001004015546,\n",
       "   0.7500001001042161],\n",
       "  [0.7500001000386647,\n",
       "   0.7500001004789598,\n",
       "   0.7500001004574884,\n",
       "   0.7500001004954437,\n",
       "   0.7500001000369473],\n",
       "  [0.7500001009856146,\n",
       "   0.7500001007101517,\n",
       "   0.750000100474211,\n",
       "   0.7500001002413479,\n",
       "   0.7500001003647239],\n",
       "  [0.7500001002858654,\n",
       "   0.750000101045961,\n",
       "   0.7500001005447047,\n",
       "   0.7500001005957949,\n",
       "   0.7500001010702144],\n",
       "  [0.7500001005370577,\n",
       "   0.7500001002521477,\n",
       "   0.7500001008698175,\n",
       "   0.7500001006182621,\n",
       "   0.7500001001199998],\n",
       "  [0.7500001004443159,\n",
       "   0.7500001005701198,\n",
       "   0.7500001008885596,\n",
       "   0.7500001006822121,\n",
       "   0.7500001004453438]]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.decrypt().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tens1 = ts.PlainTensor([1,2.5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tenseal.tensors.ckkstensor.CKKSTensor at 0x166e516f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = ts.ckks_tensor(context,tens1)\n",
    "e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0000000007035317, 2.5000000002879323, 3.0000000017075275]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1.decrypt().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting phe\n",
      "  Downloading phe-1.5.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m411.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: phe\n",
      "\u001b[33m  WARNING: The script pheutil is installed in '/Library/Frameworks/Python.framework/Versions/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed phe-1.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install phe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phe import paillier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_key,private_key = paillier.generate_paillier_keypair()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PaillierPublicKey 11d8b32a14>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting syft\n",
      "  Downloading syft-0.6.0-py2.py3-none-any.whl (606 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.0/607.0 kB\u001b[0m \u001b[31m285.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug==2.0.2\n",
      "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.9/288.9 kB\u001b[0m \u001b[31m187.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cachetools==4.2.4\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting syft\n",
      "  Downloading syft-0.5.1-py2.py3-none-any.whl (448 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.6/448.6 kB\u001b[0m \u001b[31m137.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from syft) (1.12.1)\n",
      "Collecting syft-proto\n",
      "  Downloading syft_proto-0.5.3-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m336.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting websocket-client\n",
      "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m396.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dpcontracts\n",
      "  Downloading dpcontracts-0.6.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting requests-toolbelt\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m343.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cryptography>=3.4.7\n",
      "  Downloading cryptography-38.0.3-cp36-abi3-macosx_10_10_universal2.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m342.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from syft) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from syft) (1.1.2)\n",
      "Collecting PyNaCl\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-macosx_10_10_universal2.whl (349 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.9/349.9 kB\u001b[0m \u001b[31m437.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sqlitedict\n",
      "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m519.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from syft) (6.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from syft) (21.3)\n",
      "Collecting loguru\n",
      "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from syft) (4.3.0)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from syft) (0.13.1)\n",
      "Requirement already satisfied: protobuf<=3.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from syft) (3.19.6)\n",
      "Collecting flask<2.0.0,>=1.1.2\n",
      "  Downloading Flask-1.1.4-py2.py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m559.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting names\n",
      "  Downloading names-0.3.0.tar.gz (789 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.1/789.1 kB\u001b[0m \u001b[31m619.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from syft) (1.5.5)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from syft) (1.4.4)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-10.0.0-cp310-cp310-macosx_11_0_arm64.whl (22.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.6/22.6 MB\u001b[0m \u001b[31m460.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting aiortc\n",
      "  Downloading aiortc-1.3.2-cp310-cp310-macosx_11_0_arm64.whl (867 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m497.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from syft) (2.28.1)\n",
      "Collecting pyOpenSSL\n",
      "  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m508.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting PyJWT==1.7.1\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: cachetools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from syft) (5.2.0)\n",
      "Collecting forbiddenfruit>=0.1.3\n",
      "  Downloading forbiddenfruit-0.1.4.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m486.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cryptography>=3.4.7->syft) (1.15.1)\n",
      "Collecting click<8.0,>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m347.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting itsdangerous<2.0,>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Werkzeug<2.0,>=0.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.6/298.6 kB\u001b[0m \u001b[31m388.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting Jinja2<3.0,>=2.10.1\n",
      "  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m618.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyee>=9.0.0\n",
      "  Downloading pyee-9.0.4-py2.py3-none-any.whl (14 kB)\n",
      "Collecting av<10.0.0,>=9.0.0\n",
      "  Downloading av-9.2.0-cp310-cp310-macosx_11_0_arm64.whl (20.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m348.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting aioice<0.8.0,>=0.7.5\n",
      "  Downloading aioice-0.7.6-py3-none-any.whl (23 kB)\n",
      "Collecting pylibsrtp>=0.5.6\n",
      "  Downloading pylibsrtp-0.7.1-cp310-cp310-macosx_11_0_arm64.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-crc32c>=1.1\n",
      "  Downloading google_crc32c-1.5.0-cp310-cp310-macosx_10_9_universal2.whl (32 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging->syft) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->syft) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->syft) (1.23.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->syft) (2022.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->syft) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->syft) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->syft) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->syft) (2.1.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn->syft) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn->syft) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn->syft) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision->syft) (9.2.0)\n",
      "Collecting netifaces\n",
      "  Downloading netifaces-0.11.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: dnspython>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aioice<0.8.0,>=0.7.5->aiortc->syft) (2.2.1)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.4.7->syft) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from Jinja2<3.0,>=2.10.1->flask<2.0.0,>=1.1.2->syft) (2.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->syft) (1.16.0)\n",
      "Building wheels for collected packages: forbiddenfruit, dpcontracts, names, sqlitedict, netifaces\n",
      "  Building wheel for forbiddenfruit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for forbiddenfruit: filename=forbiddenfruit-0.1.4-py3-none-any.whl size=21792 sha256=e43cc767b77f828cbe7fb829e26b758027c20cc8e4688925b75d4bdf8a8119e3\n",
      "  Stored in directory: /Users/tarunvisvar/Library/Caches/pip/wheels/80/70/bf/aa982a6b9e2c007a1d444743074a9405c144809d1110cd7612\n",
      "  Building wheel for dpcontracts (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dpcontracts: filename=dpcontracts-0.6.0-py3-none-any.whl size=13085 sha256=225938833900af55bd1778fca041d0be52ffbf2475dc3d1329f36337506d33b2\n",
      "  Stored in directory: /Users/tarunvisvar/Library/Caches/pip/wheels/9c/3c/41/ea707c90a271e9f3cdc6f271420197142b0d815f2582280430\n",
      "  Building wheel for names (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for names: filename=names-0.3.0-py3-none-any.whl size=803682 sha256=9a930ff91cb69b5a1adb4ada2fc8765b2af1496540a80aeacef832ddc29e6ece\n",
      "  Stored in directory: /Users/tarunvisvar/Library/Caches/pip/wheels/f9/3e/43/632ba1676e3504ef23705d8402a5114c291fd825bb08480031\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15734 sha256=7480d4763fd745611de5707cee2fab18caadfade43d014536664dc518cb2cfdc\n",
      "  Stored in directory: /Users/tarunvisvar/Library/Caches/pip/wheels/c5/10/9a/59753c0bfe5fe1a6f6253329e66b953962c9dc7e3201c20e0e\n",
      "  Building wheel for netifaces (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for netifaces: filename=netifaces-0.11.0-cp310-cp310-macosx_10_9_universal2.whl size=19294 sha256=8e1e5f1b5971740a34855f4df9d53d45884ca0f33f30e77d4c407ee4a1ac6d6e\n",
      "  Stored in directory: /Users/tarunvisvar/Library/Caches/pip/wheels/7d/b1/e1/3ede1298500e1f629308001a415b8e8d214655d5e8c968f09b\n",
      "Successfully built forbiddenfruit dpcontracts names sqlitedict netifaces\n",
      "Installing collected packages: sqlitedict, PyJWT, netifaces, names, forbiddenfruit, av, Werkzeug, websocket-client, syft-proto, pyee, pyarrow, loguru, Jinja2, itsdangerous, google-crc32c, dpcontracts, click, aioice, requests-toolbelt, PyNaCl, pylibsrtp, flask, cryptography, pyOpenSSL, aiortc, syft\n",
      "\u001b[33m  WARNING: The script pyjwt is installed in '/Library/Frameworks/Python.framework/Versions/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script names is installed in '/Library/Frameworks/Python.framework/Versions/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script pyav is installed in '/Library/Frameworks/Python.framework/Versions/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 2.2.2\n",
      "    Uninstalling Werkzeug-2.2.2:\n",
      "      Successfully uninstalled Werkzeug-2.2.2\n",
      "\u001b[33m  WARNING: The script wsdump is installed in '/Library/Frameworks/Python.framework/Versions/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script plasma_store is installed in '/Library/Frameworks/Python.framework/Versions/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 3.1.2\n",
      "    Uninstalling Jinja2-3.1.2:\n",
      "      Successfully uninstalled Jinja2-3.1.2\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.3\n",
      "    Uninstalling click-8.1.3:\n",
      "      Successfully uninstalled click-8.1.3\n",
      "\u001b[33m  WARNING: The script flask is installed in '/Library/Frameworks/Python.framework/Versions/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts syft-device, syft-domain, syft-network and syft-proto are installed in '/Library/Frameworks/Python.framework/Versions/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "nbconvert 6.5.2 requires jinja2>=3.0, but you have jinja2 2.11.3 which is incompatible.\n",
      "fiftyone 0.17.2 requires Jinja2>=3, but you have jinja2 2.11.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Jinja2-2.11.3 PyJWT-1.7.1 PyNaCl-1.5.0 Werkzeug-1.0.1 aioice-0.7.6 aiortc-1.3.2 av-9.2.0 click-7.1.2 cryptography-38.0.3 dpcontracts-0.6.0 flask-1.1.4 forbiddenfruit-0.1.4 google-crc32c-1.5.0 itsdangerous-1.1.0 loguru-0.6.0 names-0.3.0 netifaces-0.11.0 pyOpenSSL-22.1.0 pyarrow-10.0.0 pyee-9.0.4 pylibsrtp-0.7.1 requests-toolbelt-0.10.1 sqlitedict-2.0.0 syft-0.5.1 syft-proto-0.5.3 websocket-client-1.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install syft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement syft.frameworks (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for syft.frameworks\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install syft.frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tenseal' has no attribute 'generate_ckks_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model notebook.ipynb Cell 40\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ts\u001b[39m.\u001b[39;49mgenerate_ckks_keys()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tenseal' has no attribute 'generate_ckks_keys'"
     ]
    }
   ],
   "source": [
    "ts.generate_ckks_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'frameworks' from 'syft' (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/syft/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model notebook.ipynb Cell 41\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msyft\u001b[39;00m \u001b[39mimport\u001b[39;00m frameworks\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'frameworks' from 'syft' (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/syft/__init__.py)"
     ]
    }
   ],
   "source": [
    "from syft import frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/tarunvisvar/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 158, in _start_notebook\n",
      "\u001b[1;31m    from notebook import notebookapp as app\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/notebook/notebookapp.py\", line 43, in <module>\n",
      "\u001b[1;31m    from jinja2 import Environment, FileSystemLoader\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jinja2/__init__.py\", line 12, in <module>\n",
      "\u001b[1;31m    from .environment import Environment\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jinja2/environment.py\", line 25, in <module>\n",
      "\u001b[1;31m    from .defaults import BLOCK_END_STRING\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jinja2/defaults.py\", line 3, in <module>\n",
      "\u001b[1;31m    from .filters import FILTERS as DEFAULT_FILTERS  # noqa: F401\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jinja2/filters.py\", line 13, in <module>\n",
      "\u001b[1;31m    from markupsafe import soft_unicode\n",
      "\u001b[1;31mImportError: cannot import name 'soft_unicode' from 'markupsafe' (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/markupsafe/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/tarunvisvar/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/daemon/daemon_python.py\", line 54, in _decorator\n",
      "\u001b[1;31m    return func(self, *args, **kwargs)\n",
      "\u001b[1;31m  File \"/Users/tarunvisvar/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 111, in m_exec_module_observable\n",
      "\u001b[1;31m    self._start_notebook(args, cwd, env)\n",
      "\u001b[1;31m  File \"/Users/tarunvisvar/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 160, in _start_notebook\n",
      "\u001b[1;31m    from notebook import app as app\n",
      "\u001b[1;31mImportError: cannot import name 'app' from 'notebook' (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/notebook/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mFailed to run jupyter as observable with args notebook --no-browser --notebook-dir=\"/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code with HE\" --config=/var/folders/h7/9g4hh_gn7yqb1zvrc8q0v24w0000gn/T/c56d3021-5f90-45ca-a88e-99f12d768415/jupyter_notebook_config.py --NotebookApp.iopub_data_rate_limit=10000000000.0. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(10)\n",
    "b = torch.zeros(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'syft.frameworks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model notebook.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code/Model%20notebook.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msyft\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframeworks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtenseal\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'syft.frameworks'"
     ]
    }
   ],
   "source": [
    "import syft.frameworks.tenseal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting phe\n",
      "  Using cached phe-1.5.0-py2.py3-none-any.whl (53 kB)\n",
      "Installing collected packages: phe\n",
      "Successfully installed phe-1.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install phe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp39-none-macosx_10_9_x86_64.whl (137.9 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/137.9 MB\u001b[0m \u001b[31m164.6 kB/s\u001b[0m eta \u001b[36m0:10:33\u001b[0m"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/tarunvisvar/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 158, in _start_notebook\n",
      "\u001b[1;31m    from notebook import notebookapp as app\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/notebook/notebookapp.py\", line 43, in <module>\n",
      "\u001b[1;31m    from jinja2 import Environment, FileSystemLoader\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jinja2/__init__.py\", line 12, in <module>\n",
      "\u001b[1;31m    from .environment import Environment\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jinja2/environment.py\", line 25, in <module>\n",
      "\u001b[1;31m    from .defaults import BLOCK_END_STRING\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jinja2/defaults.py\", line 3, in <module>\n",
      "\u001b[1;31m    from .filters import FILTERS as DEFAULT_FILTERS  # noqa: F401\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jinja2/filters.py\", line 13, in <module>\n",
      "\u001b[1;31m    from markupsafe import soft_unicode\n",
      "\u001b[1;31mImportError: cannot import name 'soft_unicode' from 'markupsafe' (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/markupsafe/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/tarunvisvar/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/daemon/daemon_python.py\", line 54, in _decorator\n",
      "\u001b[1;31m    return func(self, *args, **kwargs)\n",
      "\u001b[1;31m  File \"/Users/tarunvisvar/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 111, in m_exec_module_observable\n",
      "\u001b[1;31m    self._start_notebook(args, cwd, env)\n",
      "\u001b[1;31m  File \"/Users/tarunvisvar/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 160, in _start_notebook\n",
      "\u001b[1;31m    from notebook import app as app\n",
      "\u001b[1;31mImportError: cannot import name 'app' from 'notebook' (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/notebook/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mFailed to run jupyter as observable with args notebook --no-browser --notebook-dir=\"/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code with HE\" --config=/var/folders/h7/9g4hh_gn7yqb1zvrc8q0v24w0000gn/T/9bbcebb2-24af-47c8-bcc9-4aa137f5f8a1/jupyter_notebook_config.py --NotebookApp.iopub_data_rate_limit=10000000000.0. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from phe import paillier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/tarunvisvar/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 158, in _start_notebook\n",
      "\u001b[1;31m    from notebook import notebookapp as app\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/notebook/notebookapp.py\", line 43, in <module>\n",
      "\u001b[1;31m    from jinja2 import Environment, FileSystemLoader\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jinja2/__init__.py\", line 12, in <module>\n",
      "\u001b[1;31m    from .environment import Environment\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jinja2/environment.py\", line 25, in <module>\n",
      "\u001b[1;31m    from .defaults import BLOCK_END_STRING\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jinja2/defaults.py\", line 3, in <module>\n",
      "\u001b[1;31m    from .filters import FILTERS as DEFAULT_FILTERS  # noqa: F401\n",
      "\u001b[1;31m  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jinja2/filters.py\", line 13, in <module>\n",
      "\u001b[1;31m    from markupsafe import soft_unicode\n",
      "\u001b[1;31mImportError: cannot import name 'soft_unicode' from 'markupsafe' (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/markupsafe/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/tarunvisvar/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/daemon/daemon_python.py\", line 54, in _decorator\n",
      "\u001b[1;31m    return func(self, *args, **kwargs)\n",
      "\u001b[1;31m  File \"/Users/tarunvisvar/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 111, in m_exec_module_observable\n",
      "\u001b[1;31m    self._start_notebook(args, cwd, env)\n",
      "\u001b[1;31m  File \"/Users/tarunvisvar/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 160, in _start_notebook\n",
      "\u001b[1;31m    from notebook import app as app\n",
      "\u001b[1;31mImportError: cannot import name 'app' from 'notebook' (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/notebook/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mFailed to run jupyter as observable with args notebook --no-browser --notebook-dir=\"/Users/tarunvisvar/Desktop/GitHub/Privacy-Preserved-and-Secure-Federated-Learning/Code with HE\" --config=/var/folders/h7/9g4hh_gn7yqb1zvrc8q0v24w0000gn/T/3d5cd05e-7312-4678-8f97-9cff1b536483/jupyter_notebook_config.py --NotebookApp.iopub_data_rate_limit=10000000000.0. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "public_key,private_key = paillier.generate_paillier_keypair()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h7/9g4hh_gn7yqb1zvrc8q0v24w0000gn/T/ipykernel_91524/2514857975.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
